messages:
[
	content:"
	
	I will provide you one or more Java code files .
	Find all data clumps in the respective files.
	
	A data clump exists if
	1) two methods (in the same or in different classes) have at least 3 common parameters
	    and one of those methods does not override the other,
	
	or  
	2) At least three fields in a class are common with the parameters of a method (in the same or in a different class),
	
	or
	3) Two different classes have at least three common fields
	
	## OUTPUT FORMAT
	Use the following JSON format for the output:
	
	{
	   "data_clumps":{
	        "unique_key":{
	            "key": "a unique key that should be created. It must be same as the key 'unique_key' in the 'data_clumps' object",
	            "from_file_path":"The path of the file where one part of the data clump is found",
	            "from_class_or_interface_key":"The fully qualified name of the class or interface where one part of the data clump is found",
	            "from_class_or_interface_name":"The name of the class or interface where one part of the data clump is found",
	            
	            "from_method_key":"The fully qualified name of the method where one part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	            "from_method_name":"The name of the method where one part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	
	            "to_file_path":"The path of the file where the  other part of the data clump is found",
	            "to_class_or_interface_key":"The fully qualified name of the class or interface where the  other part part of the data clump is found",
	            "to_class_or_interface_name":"The name of the class or interface where the  other  part of the data clump is found",
	            
	            "to_method_key":"The fully qualified name of the method where the  other part part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	            "to_method_name":"The name of the method where the  other  part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	            "data_clump_data":{
	                // for each data clump variable
	                "other_unique_key":{
	                    "key":"a unique key that should be created. It must be same as the key 'other_unique_key' in the 'data_clump_data' object",
	                    "name": "The name of the data clump variable that exists on the one part of the data clump",
	                    "type": "The type of the data clump variable that exists on the one part of the data clump",
	                    "displayedType": "The  type of the data clump variable, as it appears in the source code, that exists on the one part of the data clump",
	                    
	                    "position": {
	                        "startLine": "The line number of the  data clump variable on the one part of the data clump.This must be relative to the file",
	                        "startColumn": "The column number of the data clump variable on the one part of the data clump"
	                    },
	                    "to_variable":{
	                        "key":"a unique key that should be created.",
	                        "name": "The name of the data clump variable that exists on the other part of the data clump",
	                        "type": "The type of the data clump variable, as it appears in the source code, that exists on the other part of the data clump",
	                        "position": {
	                            "startLine": "The line number of the  data clump variable on the other part of the data clump. This must be relative to the file",
	                            "startColumn": "The column number of the data clump variable on the other part of the data clump",
	                        }
	                    }
	                }
	            }
	        }
	   }
	}
	
	## END OUTPUT FORMAT
		
",
	role:"
	system	
",
,
	content:
{
			dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/src/main/java/org/apache/dolphinscheduler/plugin/datasource/api/constants/DataSourceConstants.java:
		[
			fromLine:"			17",
			toLine:"			480",
			content:"
			
			package org.apache.dolphinscheduler.plugin.datasource.api.constants;
			
			import org.apache.dolphinscheduler.common.constants.DateConstants;
			
			import java.time.Duration;
			import java.util.Set;
			import java.util.regex.Pattern;
			
			import lombok.experimental.UtilityClass;
			
			import com.google.common.collect.Sets;
			
			@UtilityClass
			public class DataSourceConstants {
			
			    public static final String ORG_POSTGRESQL_DRIVER = "org.postgresql.Driver";
			    public static final String COM_MYSQL_CJ_JDBC_DRIVER = "com.mysql.cj.jdbc.Driver";
			    public static final String COM_MYSQL_JDBC_DRIVER = "com.mysql.jdbc.Driver";
			    public static final String ORG_APACHE_HIVE_JDBC_HIVE_DRIVER = "org.apache.hive.jdbc.HiveDriver";
			    public static final String COM_CLICKHOUSE_JDBC_DRIVER = "com.clickhouse.jdbc.ClickHouseDriver";
			    public static final String COM_DATABEND_JDBC_DRIVER = "com.databend.jdbc.DatabendDriver";
			    public static final String COM_ORACLE_JDBC_DRIVER = "oracle.jdbc.OracleDriver";
			    public static final String COM_SQLSERVER_JDBC_DRIVER = "com.microsoft.sqlserver.jdbc.SQLServerDriver";
			    public static final String COM_DB2_JDBC_DRIVER = "com.ibm.db2.jcc.DB2Driver";
			    public static final String COM_PRESTO_JDBC_DRIVER = "com.facebook.presto.jdbc.PrestoDriver";
			    public static final String COM_REDSHIFT_JDBC_DRIVER = "com.amazon.redshift.jdbc42.Driver";
			    public static final String COM_ATHENA_JDBC_DRIVER = "com.simba.athena.jdbc.Driver";
			    public static final String COM_TRINO_JDBC_DRIVER = "io.trino.jdbc.TrinoDriver";
			    public static final String COM_DAMENG_JDBC_DRIVER = "dm.jdbc.driver.DmDriver";
			    public static final String ORG_APACHE_KYUUBI_JDBC_DRIVER = "org.apache.kyuubi.jdbc.KyuubiHiveDriver";
			    public static final String COM_OCEANBASE_JDBC_DRIVER = "com.oceanbase.jdbc.Driver";
			    public static final String NET_SNOWFLAKE_JDBC_DRIVER = "net.snowflake.client.jdbc.SnowflakeDriver";
			    public static final String COM_VERTICA_JDBC_DRIVER = "com.vertica.jdbc.Driver";
			    public static final String COM_HANA_DB_JDBC_DRIVER = "com.sap.db.jdbc.Driver";
			
			    public static final String JDBC_MYSQL = "jdbc:mysql://";
			    public static final String JDBC_MYSQL_LOADBALANCE = "jdbc:mysql:loadbalance://";
			    public static final String JDBC_POSTGRESQL = "jdbc:postgresql://";
			    public static final String JDBC_HIVE_2 = "jdbc:hive2://";
			    public static final String JDBC_KYUUBI = "jdbc:kyuubi://";
			    public static final String JDBC_CLICKHOUSE = "jdbc:clickhouse://";
			    public static final String JDBC_DATABEND = "jdbc:databend://";
			    public static final String JDBC_ORACLE_SID = "jdbc:oracle:thin:@";
			    public static final String JDBC_ORACLE_SERVICE_NAME = "jdbc:oracle:thin:@//";
			    public static final String JDBC_SQLSERVER = "jdbc:sqlserver://";
			    public static final String JDBC_DB2 = "jdbc:db2://";
			    public static final String JDBC_PRESTO = "jdbc:presto://";
			    public static final String JDBC_REDSHIFT = "jdbc:redshift://";
			    public static final String JDBC_REDSHIFT_IAM = "jdbc:redshift:iam://";
			    public static final String JDBC_ATHENA = "jdbc:awsathena://";
			    public static final String JDBC_TRINO = "jdbc:trino://";
			    public static final String JDBC_DAMENG = "jdbc:dm://";
			    public static final String JDBC_OCEANBASE = "jdbc:oceanbase://";
			    public static final String JDBC_SNOWFLAKE = "jdbc:snowflake://";
			    public static final String JDBC_VERTICA = "jdbc:vertica://";
			    public static final String JDBC_HANA = "jdbc:sap://";
			
			    public static final String POSTGRESQL_VALIDATION_QUERY = "select version()";
			    public static final String MYSQL_VALIDATION_QUERY = "select 1";
			    public static final String HIVE_VALIDATION_QUERY = "select 1";
			    public static final String CLICKHOUSE_VALIDATION_QUERY = "select 1";
			    public static final String DATABEND_VALIDATION_QUERY = "select 1";
			    public static final String ORACLE_VALIDATION_QUERY = "select 1 from dual";
			    public static final String SQLSERVER_VALIDATION_QUERY = "select 1";
			    public static final String DB2_VALIDATION_QUERY = "select 1 from sysibm.sysdummy1";
			    public static final String PRESTO_VALIDATION_QUERY = "select 1";
			    public static final String REDHIFT_VALIDATION_QUERY = "select 1";
			    public static final String ATHENA_VALIDATION_QUERY = "select 1";
			    public static final String TRINO_VALIDATION_QUERY = "select 1";
			    public static final String DAMENG_VALIDATION_QUERY = "select 1";
			    public static final String SNOWFLAKE_VALIDATION_QUERY = "select 1";
			
			    public static final String KYUUBI_VALIDATION_QUERY = "select 1";
			    public static final String VERTICA_VALIDATION_QUERY = "select 1";
			
			    public static final String HANA_VALIDATION_QUERY = "select 1 from DUMMY";
			
			    public static final String SPRING_DATASOURCE_MIN_IDLE = "spring.datasource.minIdle";
			
			    public static final String SPRING_DATASOURCE_MAX_ACTIVE = "spring.datasource.maxActive";
			
			    public static final String SUPPORT_HIVE_ONE_SESSION = "support.hive.oneSession";
			    /**
			     * QUESTION ?
			     */
			    public static final String QUESTION = "?";
			
			    /**
			     * comma ,
			     */
			    public static final String COMMA = ",";
			
			    /**
			     * hyphen
			     */
			    public static final String HYPHEN = "-";
			
			    /**
			     * slash /
			     */
			    public static final String SLASH = "/";
			
			    /**
			     * COLON :
			     */
			    public static final String COLON = ":";
			
			    /**
			     * SPACE " "
			     */
			    public static final String SPACE = " ";
			
			    /**
			     * SINGLE_SLASH /
			     */
			    public static final String SINGLE_SLASH = "/";
			
			    /**
			     * DOUBLE_SLASH //
			     */
			    public static final String DOUBLE_SLASH = "//";
			
			    /**
			     * SINGLE_QUOTES "'"
			     */
			    public static final String SINGLE_QUOTES = "'";
			    /**
			     * DOUBLE_QUOTES "\""
			     */
			    public static final String DOUBLE_QUOTES = "\"";
			
			    /**
			     * SEMICOLON ;
			     */
			    public static final String SEMICOLON = ";";
			
			    /**
			     * EQUAL SIGN
			     */
			    public static final String EQUAL_SIGN = "=";
			    /**
			     * AT SIGN
			     */
			    public static final String AT_SIGN = "@";
			    /**
			     * UNDERLINE
			     */
			    public static final String UNDERLINE = "_";
			
			    /**
			     * sleep time
			     */
			    public static final int SLEEP_TIME_MILLIS = 1000;
			
			    /**
			     * exit code failure
			     */
			    public static final int EXIT_CODE_FAILURE = -1;
			
			    /**
			     * exit code success
			     */
			    public static final int EXIT_CODE_SUCCESS = 0;
			    /**
			     * running code
			     */
			    public static final int RUNNING_CODE = 1;
			
			    public static final String SH = "sh";
			
			    /**
			     * log flush interval?output when reach the interval
			     */
			    public static final int DEFAULT_LOG_FLUSH_INTERVAL = 1000;
			
			    /**
			     * pstree, get pud and sub pid
			     */
			    public static final String PSTREE = "pstree";
			
			    public static final String RWXR_XR_X = "rwxr-xr-x";
			
			    /**
			     * date format of yyyyMMddHHmmss
			     */
			    public static final String PARAMETER_FORMAT_TIME = "yyyyMMddHHmmss";
			
			    /**
			     * new
			     * schedule time
			     */
			    public static final String PARAMETER_SHECDULE_TIME = "schedule.time";
			
			    /**
			     * system date(yyyyMMddHHmmss)
			     */
			    public static final String PARAMETER_DATETIME = DateConstants.PARAMETER_DATETIME;
			
			    /**
			     * system date(yyyymmdd) today
			     */
			    public static final String PARAMETER_CURRENT_DATE = DateConstants.PARAMETER_CURRENT_DATE;
			
			    /**
			     * system date(yyyymmdd) yesterday
			     */
			    public static final String PARAMETER_BUSINESS_DATE = DateConstants.PARAMETER_BUSINESS_DATE;
			
			    /**
			     * the absolute path of current executing task
			     */
			    public static final String PARAMETER_TASK_EXECUTE_PATH = "system.task.execute.path";
			
			    /**
			     * the instance id of current task
			     */
			    public static final String PARAMETER_TASK_INSTANCE_ID = "system.task.instance.id";
			
			    /**
			     * the definition code of current task
			     */
			    public static final String PARAMETER_TASK_DEFINITION_CODE = "system.task.definition.code";
			
			    /**
			     * the definition name of current task
			     */
			    public static final String PARAMETER_TASK_DEFINITION_NAME = "system.task.definition.name";
			
			    /**
			     * the instance id of the workflow to which current task belongs
			     */
			    public static final String PARAMETER_WORKFLOW_INSTANCE_ID = "system.workflow.instance.id";
			
			    /**
			     * the definition code of the workflow to which current task belongs
			     */
			    public static final String PARAMETER_WORKFLOW_DEFINITION_CODE = "system.workflow.definition.code";
			
			    /**
			     * the definition name of the workflow to which current task belongs
			     */
			    public static final String PARAMETER_WORKFLOW_DEFINITION_NAME = "system.workflow.definition.name";
			
			    /**
			     * the code of the project to which current task belongs
			     */
			    public static final String PARAMETER_PROJECT_CODE = "system.project.code";
			
			    /**
			     * the name of the project to which current task belongs
			     */
			    public static final String PARAMETER_PROJECT_NAME = "system.project.name";
			    /**
			     * month_begin
			     */
			    public static final String MONTH_BEGIN = "month_begin";
			    /**
			     * add_months
			     */
			    public static final String ADD_MONTHS = "add_months";
			    /**
			     * month_end
			     */
			    public static final String MONTH_END = "month_end";
			    /**
			     * week_begin
			     */
			    public static final String WEEK_BEGIN = "week_begin";
			    /**
			     * week_end
			     */
			    public static final String WEEK_END = "week_end";
			    /**
			     * this_day
			     */
			    public static final String THIS_DAY = "this_day";
			    /**
			     * last_day
			     */
			    public static final String LAST_DAY = "last_day";
			
			    /**
			     * month_first_day
			     */
			    public static final String MONTH_FIRST_DAY = "month_first_day";
			
			    /**
			     * month_last_day
			     */
			    public static final String MONTH_LAST_DAY = "month_last_day";
			
			    /**
			     * week_first_day
			     */
			    public static final String WEEK_FIRST_DAY = "week_first_day";
			
			    /**
			     * week_last_day
			     */
			    public static final String WEEK_LAST_DAY = "week_last_day";
			
			    /**
			     * year_week
			     */
			    public static final String YEAR_WEEK = "year_week";
			    /**
			     * timestamp
			     */
			    public static final String TIMESTAMP = "timestamp";
			    public static final char SUBTRACT_CHAR = '-';
			    public static final char ADD_CHAR = '+';
			    public static final char MULTIPLY_CHAR = '*';
			    public static final char DIVISION_CHAR = '/';
			    public static final char LEFT_BRACE_CHAR = '(';
			    public static final char RIGHT_BRACE_CHAR = ')';
			    public static final String ADD_STRING = "+";
			    public static final String MULTIPLY_STRING = "*";
			    public static final String DIVISION_STRING = "/";
			    public static final String LEFT_BRACE_STRING = "(";
			    public static final char P = 'P';
			    public static final char N = 'N';
			    public static final String SUBTRACT_STRING = "-";
			    public static final String LOCAL_PARAMS_LIST = "localParamsList";
			    public static final String TASK_TYPE = "taskType";
			    public static final String QUEUE = "queue";
			    /**
			     * default display rows
			     */
			    public static final int DEFAULT_DISPLAY_ROWS = 10;
			
			    /**
			     * jar
			     */
			    public static final String JAR = "jar";
			
			    /**
			     * hadoop
			     */
			    public static final String HADOOP = "hadoop";
			
			    /**
			     * -D <property>=<value>
			     */
			    public static final String D = "-D";
			
			    /**
			     * datasource encryption salt
			     */
			    public static final String DATASOURCE_ENCRYPTION_SALT_DEFAULT = "!@#$%^&*";
			    public static final String DATASOURCE_ENCRYPTION_ENABLE = "datasource.encryption.enable";
			    public static final String DATASOURCE_ENCRYPTION_SALT = "datasource.encryption.salt";
			
			    /**
			     * kerberos
			     */
			    public static final String KERBEROS = "kerberos";
			
			    /**
			     * kerberos expire time
			     */
			    public static final String KERBEROS_EXPIRE_TIME = "kerberos.expire.time";
			
			    /**
			     * java.security.krb5.conf
			     */
			    public static final String JAVA_SECURITY_KRB5_CONF = "java.security.krb5.conf";
			
			    /**
			     * java.security.krb5.conf.path
			     */
			    public static final String JAVA_SECURITY_KRB5_CONF_PATH = "java.security.krb5.conf.path";
			
			    /**
			     * loginUserFromKeytab user
			     */
			    public static final String LOGIN_USER_KEY_TAB_USERNAME = "login.user.keytab.username";
			
			    /**
			     * loginUserFromKeytab path
			     */
			    public static final String LOGIN_USER_KEY_TAB_PATH = "login.user.keytab.path";
			
			    /**
			     * hadoop.security.authentication
			     */
			    public static final String HADOOP_SECURITY_AUTHENTICATION = "hadoop.security.authentication";
			
			    /**
			     * hadoop.security.authentication
			     */
			    public static final String HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE =
			            "hadoop.security.authentication.startup.state";
			
			    /**
			     * hdfs/s3 configuration
			     * resource.storage.upload.base.path
			     */
			    public static final String RESOURCE_UPLOAD_PATH = "resource.storage.upload.base.path";
			
			    /**
			     * data.quality.jar.dir
			     */
			    public static final String DATA_QUALITY_JAR_DIR = "data-quality.jar.dir";
			
			    public static final String TASK_TYPE_DATA_QUALITY = "DATA_QUALITY";
			
			    public static final Set<String> TASK_TYPE_SET_K8S = Sets.newHashSet("K8S", "KUBEFLOW");
			
			    /**
			     * azure config
			     */
			    public static final String AZURE_CLIENT_ID = "resource.azure.client.id";
			    public static final String AZURE_CLIENT_SECRET = "resource.azure.client.secret";
			    public static final String AZURE_ACCESS_SUB_ID = "resource.azure.subId";
			    public static final String AZURE_SECRET_TENANT_ID = "resource.azure.tenant.id";
			    public static final String QUERY_INTERVAL = "resource.query.interval";
			
			    /**
			     * use for k8s task
			     */
			    public static final String API_VERSION = "batch/v1";
			    public static final String RESTART_POLICY = "Never";
			    public static final String MEMORY = "memory";
			    public static final String CPU = "cpu";
			    public static final String LAYER_LABEL = "k8s.cn/layer";
			    public static final String LAYER_LABEL_VALUE = "batch";
			    public static final String NAME_LABEL = "k8s.cn/name";
			    public static final String TASK_INSTANCE_ID = "taskInstanceId";
			    public static final String MI = "Mi";
			    public static final int JOB_TTL_SECONDS = 300;
			    public static final int LOG_LINES = 500;
			    public static final String NAMESPACE_NAME = "name";
			    public static final String CLUSTER = "cluster";
			
			    /**
			     * spark / flink on k8s label name
			     */
			    public static final String UNIQUE_LABEL_NAME = "dolphinscheduler-label";
			
			    /**
			     * conda config used by jupyter task plugin
			     */
			    public static final String CONDA_PATH = "conda.path";
			
			    // Loop task constants
			    public static final Duration DEFAULT_LOOP_STATUS_INTERVAL = Duration.ofSeconds(5L);
			
			    /**
			     * sql params regex
			     */
			    public static final String GROUP_NAME1 = "paramName1";
			    public static final String GROUP_NAME2 = "paramName2";
			    public static final String SQL_PARAMS_REGEX =
			            String.format("['\"]\\$\\{(?<%s>.*?)}['\"]|\\$\\{(?<%s>.*?)}", GROUP_NAME1, GROUP_NAME2);
			    public static final Pattern SQL_PARAMS_PATTERN = Pattern.compile(SQL_PARAMS_REGEX);
			
			    public static final String AZURE_SQL_DATABASE_SPN = "https://database.windows.net/";
			    public static final String AZURE_SQL_DATABASE_TOKEN_SCOPE = "/.default";
			
			}
						
",
,

		],
		dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/TaskConstants.java:
		[
			fromLine:"			17",
			toLine:"			27",
			content:"
			
			package org.apache.dolphinscheduler.plugin.task.api;
			
			import org.apache.dolphinscheduler.common.constants.DateConstants;
			
			import java.time.Duration;
			import java.util.Set;
			import java.util.regex.Pattern;
			
			import com.google.common.collect.Sets;
						
",
,
			fromLine:"			29",
			toLine:"			393",
			content:"
			
			    private TaskConstants() {
			        throw new IllegalStateException("Utility class");
			    }
			
			    public static final String YARN_APPLICATION_REGEX = "application_\\d+_\\d+";
			
			    public static final String FLINK_APPLICATION_REGEX = "JobID \\w+";
			
			    public static final String DATASOURCE_PASSWORD_REGEX =
			            "(?<=((?i)password((\" : \")|(\":\")|(\\\\\":\\\\\")|(=')))).*?(?=((\")|(\\\\\")|(')))";
			
			    /**
			     * exit code kill
			     */
			    public static final int EXIT_CODE_KILL = 137;
			    public static final String PID = "pid";
			
			    /**
			     * QUESTION ?
			     */
			    public static final String QUESTION = "?";
			
			    /**
			     * comma ,
			     */
			    public static final String COMMA = ",";
			
			    /**
			     * hyphen
			     */
			    public static final String HYPHEN = "-";
			
			    /**
			     * slash /
			     */
			    public static final String SLASH = "/";
			
			    /**
			     * COLON :
			     */
			    public static final String COLON = ":";
			
			    /**
			     * SPACE " "
			     */
			    public static final String SPACE = " ";
			
			    /**
			     * SINGLE_SLASH /
			     */
			    public static final String SINGLE_SLASH = "/";
			
			    /**
			     * DOUBLE_SLASH //
			     */
			    public static final String DOUBLE_SLASH = "//";
			
			    /**
			     * SINGLE_QUOTES "'"
			     */
			    public static final String SINGLE_QUOTES = "'";
			    /**
			     * DOUBLE_QUOTES "\""
			     */
			    public static final String DOUBLE_QUOTES = "\"";
			
			    /**
			     * SEMICOLON ;
			     */
			    public static final String SEMICOLON = ";";
			
			    /**
			     * EQUAL SIGN
			     */
			    public static final String EQUAL_SIGN = "=";
			
			    /**
			     * UNDERLINE
			     */
			    public static final String UNDERLINE = "_";
			
			    /**
			     * sleep time
			     */
			    public static final int SLEEP_TIME_MILLIS = 1000;
			
			    /**
			     * exit code failure
			     */
			    public static final int EXIT_CODE_FAILURE = -1;
			
			    /**
			     * exit code success
			     */
			    public static final int EXIT_CODE_SUCCESS = 0;
			    /**
			     * running code
			     */
			    public static final int RUNNING_CODE = 1;
			
			    public static final String SH = "sh";
			
			    /**
			     * log flush interval?output when reach the interval
			     */
			    public static final int DEFAULT_LOG_FLUSH_INTERVAL = 1000;
			
			    /**
			     * pstree, get pud and sub pid
			     */
			    public static final String PSTREE = "pstree";
			
			    public static final String RWXR_XR_X = "rwxr-xr-x";
			
			    /**
			     * date format of yyyyMMddHHmmss
			     */
			    public static final String PARAMETER_FORMAT_TIME = "yyyyMMddHHmmss";
			
			    /**
			     * new
			     * schedule time
			     */
			    public static final String PARAMETER_SHECDULE_TIME = "schedule.time";
			
			    /**
			     * system date(yyyyMMddHHmmss)
			     */
			    public static final String PARAMETER_DATETIME = DateConstants.PARAMETER_DATETIME;
			
			    /**
			     * system date(yyyymmdd) today
			     */
			    public static final String PARAMETER_CURRENT_DATE = DateConstants.PARAMETER_CURRENT_DATE;
			
			    /**
			     * system date(yyyymmdd) yesterday
			     */
			    public static final String PARAMETER_BUSINESS_DATE = DateConstants.PARAMETER_BUSINESS_DATE;
			
			    /**
			     * the absolute path of current executing task
			     */
			    public static final String PARAMETER_TASK_EXECUTE_PATH = "system.task.execute.path";
			
			    /**
			     * the instance id of current task
			     */
			    public static final String PARAMETER_TASK_INSTANCE_ID = "system.task.instance.id";
			
			    /**
			     * the definition code of current task
			     */
			    public static final String PARAMETER_TASK_DEFINITION_CODE = "system.task.definition.code";
			
			    /**
			     * the definition name of current task
			     */
			    public static final String PARAMETER_TASK_DEFINITION_NAME = "system.task.definition.name";
			
			    /**
			     * the instance id of the workflow to which current task belongs
			     */
			    public static final String PARAMETER_WORKFLOW_INSTANCE_ID = "system.workflow.instance.id";
			
			    /**
			     * the definition code of the workflow to which current task belongs
			     */
			    public static final String PARAMETER_WORKFLOW_DEFINITION_CODE = "system.workflow.definition.code";
			
			    /**
			     * the definition name of the workflow to which current task belongs
			     */
			    public static final String PARAMETER_WORKFLOW_DEFINITION_NAME = "system.workflow.definition.name";
			
			    /**
			     * the code of the project to which current task belongs
			     */
			    public static final String PARAMETER_PROJECT_CODE = "system.project.code";
			
			    /**
			     * the name of the project to which current task belongs
			     */
			    public static final String PARAMETER_PROJECT_NAME = "system.project.name";
			    /**
			     * month_begin
			     */
			    public static final String MONTH_BEGIN = "month_begin";
			    /**
			     * add_months
			     */
			    public static final String ADD_MONTHS = "add_months";
			    /**
			     * month_end
			     */
			    public static final String MONTH_END = "month_end";
			    /**
			     * week_begin
			     */
			    public static final String WEEK_BEGIN = "week_begin";
			    /**
			     * week_end
			     */
			    public static final String WEEK_END = "week_end";
			    /**
			     * this_day
			     */
			    public static final String THIS_DAY = "this_day";
			    /**
			     * last_day
			     */
			    public static final String LAST_DAY = "last_day";
			
			    /**
			     * month_first_day
			     */
			    public static final String MONTH_FIRST_DAY = "month_first_day";
			
			    /**
			     * month_last_day
			     */
			    public static final String MONTH_LAST_DAY = "month_last_day";
			
			    /**
			     * week_first_day
			     */
			    public static final String WEEK_FIRST_DAY = "week_first_day";
			
			    /**
			     * week_last_day
			     */
			    public static final String WEEK_LAST_DAY = "week_last_day";
			
			    /**
			     * year_week
			     */
			    public static final String YEAR_WEEK = "year_week";
			    /**
			     * timestamp
			     */
			    public static final String TIMESTAMP = "timestamp";
			    public static final char SUBTRACT_CHAR = '-';
			    public static final char ADD_CHAR = '+';
			    public static final char MULTIPLY_CHAR = '*';
			    public static final char DIVISION_CHAR = '/';
			    public static final char LEFT_BRACE_CHAR = '(';
			    public static final char RIGHT_BRACE_CHAR = ')';
			    public static final String ADD_STRING = "+";
			    public static final String MULTIPLY_STRING = "*";
			    public static final String DIVISION_STRING = "/";
			    public static final String LEFT_BRACE_STRING = "(";
			    public static final char P = 'P';
			    public static final char N = 'N';
			    public static final String SUBTRACT_STRING = "-";
			    public static final String LOCAL_PARAMS_LIST = "localParamsList";
			    public static final String TASK_TYPE = "taskType";
			    public static final String QUEUE = "queue";
			    /**
			     * default display rows
			     */
			    public static final int DEFAULT_DISPLAY_ROWS = 10;
			
			    /**
			     * jar
			     */
			    public static final String JAR = "jar";
			
			    /**
			     * hadoop
			     */
			    public static final String HADOOP = "hadoop";
			
			    /**
			     * -D <property>=<value>
			     */
			    public static final String D = "-D";
			
			    /**
			     * java.security.krb5.conf
			     */
			    public static final String JAVA_SECURITY_KRB5_CONF = "java.security.krb5.conf";
			
			    /**
			     * java.security.krb5.conf.path
			     */
			    public static final String JAVA_SECURITY_KRB5_CONF_PATH = "java.security.krb5.conf.path";
			
			    /**
			     * hadoop.security.authentication
			     */
			    public static final String HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE =
			            "hadoop.security.authentication.startup.state";
			
			    public static final String TASK_TYPE_DATA_QUALITY = "DATA_QUALITY";
			
			    public static final Set<String> TASK_TYPE_SET_K8S = Sets.newHashSet("K8S", "KUBEFLOW");
			
			    /**
			     * azure config
			     */
			    public static final String AZURE_CLIENT_ID = "resource.azure.client.id";
			    public static final String AZURE_CLIENT_SECRET = "resource.azure.client.secret";
			    public static final String AZURE_ACCESS_SUB_ID = "resource.azure.subId";
			    public static final String AZURE_SECRET_TENANT_ID = "resource.azure.tenant.id";
			    public static final String QUERY_INTERVAL = "resource.query.interval";
			
			    /**
			     * use for k8s task
			     */
			    public static final String API_VERSION = "batch/v1";
			    public static final String RESTART_POLICY = "Never";
			    public static final String MEMORY = "memory";
			    public static final String CPU = "cpu";
			    public static final String LAYER_LABEL = "k8s.cn/layer";
			    public static final String LAYER_LABEL_VALUE = "batch";
			    public static final String NAME_LABEL = "k8s.cn/name";
			    public static final String TASK_INSTANCE_ID = "taskInstanceId";
			    public static final String MI = "Mi";
			    public static final int JOB_TTL_SECONDS = 300;
			    public static final int LOG_LINES = 500;
			    public static final String NAMESPACE_NAME = "name";
			    public static final String CLUSTER = "cluster";
			
			    /**
			     * spark / flink on k8s label name
			     */
			    public static final String UNIQUE_LABEL_NAME = "dolphinscheduler-label";
			
			    /**
			     * conda config used by jupyter task plugin
			     */
			    public static final String CONDA_PATH = "conda.path";
			
			    // Loop task constants
			    public static final Duration DEFAULT_LOOP_STATUS_INTERVAL = Duration.ofSeconds(5L);
			
			    /**
			     * sql params regex
			     */
			    public static final String GROUP_NAME1 = "paramName1";
			    public static final String GROUP_NAME2 = "paramName2";
			    public static final String SQL_PARAMS_REGEX =
			            String.format("['\"]\\$\\{(?<%s>.*?)}['\"]|\\$\\{(?<%s>.*?)}", GROUP_NAME1, GROUP_NAME2);
			    public static final Pattern SQL_PARAMS_PATTERN = Pattern.compile(SQL_PARAMS_REGEX);
			
			    public static final String LOGIN_USER_KEY_TAB_USERNAME = "login.user.keytab.username";
			
			    public static final String LOGIN_USER_KEY_TAB_PATH = "login.user.keytab.path";
			
			    /**
			     * fetch applicationId way
			     */
			    public static final String APPID_COLLECT = "appId.collect";
			    public static final String DEFAULT_COLLECT_WAY = "log";
			
			    public static final String WORKFLOW_INSTANCE_ID_MDC_KEY = "workflowInstanceId";
			    public static final String TASK_INSTANCE_ID_MDC_KEY = "taskInstanceId";
			
			    public static final String STAR = "*";
			}
						
",
,

		],
		dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/constants/DataSourceConstants.java:
		[
			fromLine:"			17",
			toLine:"			132",
			content:"
			
			package org.apache.dolphinscheduler.common.constants;
			
			public class DataSourceConstants {
			
			    public static final String DATASOURCE = "datasource";
			
			    /**
			     * driver
			     */
			    public static final String ORG_POSTGRESQL_DRIVER = "org.postgresql.Driver";
			    public static final String COM_MYSQL_CJ_JDBC_DRIVER = "com.mysql.cj.jdbc.Driver";
			    public static final String COM_MYSQL_JDBC_DRIVER = "com.mysql.jdbc.Driver";
			    public static final String ORG_APACHE_HIVE_JDBC_HIVE_DRIVER = "org.apache.hive.jdbc.HiveDriver";
			    public static final String COM_CLICKHOUSE_JDBC_DRIVER = "com.clickhouse.jdbc.ClickHouseDriver";
			    public static final String COM_DATABEND_JDBC_DRIVER = "com.databend.jdbc.DatabendDriver";
			    public static final String COM_ORACLE_JDBC_DRIVER = "oracle.jdbc.OracleDriver";
			    public static final String COM_SQLSERVER_JDBC_DRIVER = "com.microsoft.sqlserver.jdbc.SQLServerDriver";
			    public static final String COM_DB2_JDBC_DRIVER = "com.ibm.db2.jcc.DB2Driver";
			    public static final String COM_PRESTO_JDBC_DRIVER = "com.facebook.presto.jdbc.PrestoDriver";
			    public static final String COM_REDSHIFT_JDBC_DRIVER = "com.amazon.redshift.jdbc42.Driver";
			    public static final String COM_ATHENA_JDBC_DRIVER = "com.simba.athena.jdbc.Driver";
			    public static final String COM_TRINO_JDBC_DRIVER = "io.trino.jdbc.TrinoDriver";
			    public static final String COM_DAMENG_JDBC_DRIVER = "dm.jdbc.driver.DmDriver";
			    public static final String ORG_APACHE_KYUUBI_JDBC_DRIVER = "org.apache.kyuubi.jdbc.KyuubiHiveDriver";
			    public static final String COM_OCEANBASE_JDBC_DRIVER = "com.oceanbase.jdbc.Driver";
			    public static final String NET_SNOWFLAKE_JDBC_DRIVER = "net.snowflake.client.jdbc.SnowflakeDriver";
			    public static final String COM_VERTICA_JDBC_DRIVER = "com.vertica.jdbc.Driver";
			    public static final String COM_HANA_DB_JDBC_DRIVER = "com.sap.db.jdbc.Driver";
			
			    /**
			     * validation Query
			     */
			    public static final String POSTGRESQL_VALIDATION_QUERY = "select version()";
			    public static final String MYSQL_VALIDATION_QUERY = "select 1";
			    public static final String HIVE_VALIDATION_QUERY = "select 1";
			    public static final String CLICKHOUSE_VALIDATION_QUERY = "select 1";
			    public static final String DATABEND_VALIDATION_QUERY = "select 1";
			    public static final String ORACLE_VALIDATION_QUERY = "select 1 from dual";
			    public static final String SQLSERVER_VALIDATION_QUERY = "select 1";
			    public static final String DB2_VALIDATION_QUERY = "select 1 from sysibm.sysdummy1";
			    public static final String PRESTO_VALIDATION_QUERY = "select 1";
			    public static final String REDHIFT_VALIDATION_QUERY = "select 1";
			    public static final String ATHENA_VALIDATION_QUERY = "select 1";
			    public static final String TRINO_VALIDATION_QUERY = "select 1";
			    public static final String DAMENG_VALIDATION_QUERY = "select 1";
			    public static final String SNOWFLAKE_VALIDATION_QUERY = "select 1";
			
			    public static final String KYUUBI_VALIDATION_QUERY = "select 1";
			    public static final String VERTICA_VALIDATION_QUERY = "select 1";
			
			    public static final String HANA_VALIDATION_QUERY = "select 1 from DUMMY";
			
			    /**
			     * jdbc url
			     */
			    public static final String JDBC_MYSQL = "jdbc:mysql://";
			    public static final String JDBC_MYSQL_LOADBALANCE = "jdbc:mysql:loadbalance://";
			    public static final String JDBC_POSTGRESQL = "jdbc:postgresql://";
			    public static final String JDBC_HIVE_2 = "jdbc:hive2://";
			    public static final String JDBC_KYUUBI = "jdbc:kyuubi://";
			    public static final String JDBC_CLICKHOUSE = "jdbc:clickhouse://";
			    public static final String JDBC_DATABEND = "jdbc:databend://";
			    public static final String JDBC_ORACLE_SID = "jdbc:oracle:thin:@";
			    public static final String JDBC_ORACLE_SERVICE_NAME = "jdbc:oracle:thin:@//";
			    public static final String JDBC_SQLSERVER = "jdbc:sqlserver://";
			    public static final String JDBC_DB2 = "jdbc:db2://";
			    public static final String JDBC_PRESTO = "jdbc:presto://";
			    public static final String JDBC_REDSHIFT = "jdbc:redshift://";
			    public static final String JDBC_REDSHIFT_IAM = "jdbc:redshift:iam://";
			    public static final String JDBC_ATHENA = "jdbc:awsathena://";
			    public static final String JDBC_TRINO = "jdbc:trino://";
			    public static final String JDBC_DAMENG = "jdbc:dm://";
			    public static final String JDBC_OCEANBASE = "jdbc:oceanbase://";
			    public static final String JDBC_SNOWFLAKE = "jdbc:snowflake://";
			    public static final String JDBC_VERTICA = "jdbc:vertica://";
			    public static final String JDBC_HANA = "jdbc:sap://";
			
			    /**
			     * database type
			     */
			    public static final String MYSQL = "MYSQL";
			    public static final String HIVE = "HIVE";
			
			    /**
			     * dataSource sensitive param
			     */
			    public static final String DATASOURCE_PASSWORD_REGEX =
			            "(?<=((?i)password((\" : \")|(\":\")|(\\\\\":\\\\\")|(=')))).*?(?=((\")|(\\\\\")|(')))";
			
			    /**
			     * datasource encryption salt
			     */
			    public static final String DATASOURCE_ENCRYPTION_SALT_DEFAULT = "!@#$%^&*";
			    public static final String DATASOURCE_ENCRYPTION_ENABLE = "datasource.encryption.enable";
			    public static final String DATASOURCE_ENCRYPTION_SALT = "datasource.encryption.salt";
			
			    /**
			     * datasource config
			     */
			    public static final String SPRING_DATASOURCE_MIN_IDLE = "spring.datasource.minIdle";
			
			    public static final String SPRING_DATASOURCE_MAX_ACTIVE = "spring.datasource.maxActive";
			
			    public static final String SPRING_DATASOURCE_TEST_ON_BORROW = "spring.datasource.testOnBorrow";
			
			    /**
			     * azure static websites
			     */
			    public static final String AZURE_SQL_DATABASE_SPN = "https://database.windows.net/";
			    public static final String AZURE_SQL_DATABASE_TOKEN_SCOPE = "/.default";
			
			}
						
",
,

		],
		dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java:
		[
			fromLine:"			17",
			toLine:"			148",
			content:"
			
			package org.apache.dolphinscheduler.dao.entity;
			
			import org.apache.dolphinscheduler.common.enums.Flag;
			import org.apache.dolphinscheduler.common.enums.Priority;
			import org.apache.dolphinscheduler.common.enums.TaskExecuteType;
			import org.apache.dolphinscheduler.plugin.task.api.enums.TaskExecutionStatus;
			
			import java.io.Serializable;
			import java.util.Date;
			
			import lombok.Data;
			
			import com.baomidou.mybatisplus.annotation.FieldStrategy;
			import com.baomidou.mybatisplus.annotation.IdType;
			import com.baomidou.mybatisplus.annotation.TableField;
			import com.baomidou.mybatisplus.annotation.TableId;
			import com.baomidou.mybatisplus.annotation.TableName;
			
			@Data
			@TableName("t_ds_task_instance")
			public class TaskInstance implements Serializable {
			
			    @TableId(value = "id", type = IdType.AUTO)
			    private Integer id;
			
			    private String name;
			
			    private String taskType;
			
			    private int workflowInstanceId;
			
			    private String workflowInstanceName;
			
			    private Long projectCode;
			
			    private long taskCode;
			
			    private int taskDefinitionVersion;
			
			    @TableField(exist = false)
			    private String processDefinitionName;
			
			    @TableField(exist = false)
			    private int taskGroupPriority;
			
			    private TaskExecutionStatus state;
			
			    private Date firstSubmitTime;
			
			    private Date submitTime;
			
			    private Date startTime;
			
			    private Date endTime;
			
			    private String host;
			
			    private String executePath;
			
			    private String logPath;
			
			    private int retryTimes;
			
			    private Flag alertFlag;
			
			    @TableField(exist = false)
			    private WorkflowInstance workflowInstance;
			
			    @TableField(exist = false)
			    private WorkflowDefinition workflowDefinition;
			
			    @TableField(exist = false)
			    private TaskDefinition taskDefine;
			
			    private int pid;
			
			    private String appLink;
			
			    private Flag flag;
			
			    private Flag isCache;
			
			    @TableField(updateStrategy = FieldStrategy.IGNORED)
			    private String cacheKey;
			
			    @TableField(exist = false)
			    private String duration;
			
			    private int maxRetryTimes;
			
			    private int retryInterval;
			
			    private Priority taskInstancePriority;
			
			    @TableField(exist = false)
			    private Priority workflowInstancePriority;
			
			    private String workerGroup;
			
			    private Long environmentCode;
			
			    private String environmentConfig;
			
			    private int executorId;
			
			    private String varPool;
			
			    private String executorName;
			
			    private int delayTime;
			
			    private String taskParams;
			
			    private int dryRun;
			
			    private int taskGroupId;
			
			    private Integer cpuQuota;
			
			    private Integer memoryMax;
			
			    private TaskExecuteType taskExecuteType;
			
			    private int testFlag;
			
			    public void init(String host, Date startTime, String executePath) {
			        this.host = host;
			        this.startTime = startTime;
			        this.executePath = executePath;
			    }
						
",
,

		],
		dolphinscheduler-extract/dolphinscheduler-extract-master/src/main/java/org/apache/dolphinscheduler/extract/master/dto/TaskInstanceExecuteDto.java:
		[
			fromLine:"			17",
			toLine:"			116",
			content:"
			
			package org.apache.dolphinscheduler.extract.master.dto;
			
			import org.apache.dolphinscheduler.common.enums.Flag;
			import org.apache.dolphinscheduler.common.enums.Priority;
			import org.apache.dolphinscheduler.common.enums.TaskExecuteType;
			import org.apache.dolphinscheduler.plugin.task.api.enums.TaskExecutionStatus;
			
			import java.util.Date;
			import java.util.Map;
			
			import lombok.Data;
			
			@Data
			public class TaskInstanceExecuteDto {
			
			    private int id;
			
			    private String name;
			
			    private String taskType;
			
			    private int processInstanceId;
			
			    private long taskCode;
			
			    private int taskDefinitionVersion;
			
			    private String processInstanceName;
			
			    private int taskGroupPriority;
			
			    private TaskExecutionStatus state;
			
			    private Date firstSubmitTime;
			
			    private Date submitTime;
			
			    private Date startTime;
			
			    private Date endTime;
			
			    private String host;
			
			    private String executePath;
			
			    private String logPath;
			
			    private int retryTimes;
			
			    private Flag alertFlag;
			
			    private int pid;
			
			    private String appLink;
			
			    private Flag flag;
			
			    private String duration;
			
			    private int maxRetryTimes;
			
			    private int retryInterval;
			
			    private Priority taskInstancePriority;
			
			    private Priority processInstancePriority;
			
			    private String workerGroup;
			
			    private Long environmentCode;
			
			    private String environmentConfig;
			
			    private int executorId;
			
			    private String varPool;
			
			    private String executorName;
			
			    private Map<String, String> resources;
			
			    private int delayTime;
			
			    private String taskParams;
			
			    private int dryRun;
			
			    private int taskGroupId;
			
			    private Integer cpuQuota;
			
			    private Integer memoryMax;
			
			    private TaskExecuteType taskExecuteType;
			}
						
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java:
		[
			fromLine:"			17",
			toLine:"			58",
			content:"
			
			package org.apache.dolphinscheduler.api.controller;
			
			import static org.apache.dolphinscheduler.api.enums.Status.CREATE_ACCESS_TOKEN_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.DELETE_ACCESS_TOKEN_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.GENERATE_TOKEN_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ACCESSTOKEN_BY_USER_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ACCESSTOKEN_LIST_PAGING_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_ACCESS_TOKEN_ERROR;
			
			import org.apache.dolphinscheduler.api.audit.OperatorLog;
			import org.apache.dolphinscheduler.api.audit.enums.AuditType;
			import org.apache.dolphinscheduler.api.exceptions.ApiException;
			import org.apache.dolphinscheduler.api.service.AccessTokenService;
			import org.apache.dolphinscheduler.api.utils.PageInfo;
			import org.apache.dolphinscheduler.api.utils.Result;
			import org.apache.dolphinscheduler.common.constants.Constants;
			import org.apache.dolphinscheduler.dao.entity.AccessToken;
			import org.apache.dolphinscheduler.dao.entity.User;
			import org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils;
			
			import java.util.List;
			
			import org.springframework.beans.factory.annotation.Autowired;
			import org.springframework.http.HttpStatus;
			import org.springframework.web.bind.annotation.DeleteMapping;
			import org.springframework.web.bind.annotation.GetMapping;
			import org.springframework.web.bind.annotation.PathVariable;
			import org.springframework.web.bind.annotation.PostMapping;
			import org.springframework.web.bind.annotation.PutMapping;
			import org.springframework.web.bind.annotation.RequestAttribute;
			import org.springframework.web.bind.annotation.RequestMapping;
			import org.springframework.web.bind.annotation.RequestParam;
			import org.springframework.web.bind.annotation.ResponseStatus;
			import org.springframework.web.bind.annotation.RestController;
			
			import io.swagger.v3.oas.annotations.Operation;
			import io.swagger.v3.oas.annotations.Parameter;
			import io.swagger.v3.oas.annotations.Parameters;
			import io.swagger.v3.oas.annotations.media.Schema;
			import io.swagger.v3.oas.annotations.tags.Tag;
						
",
,
			fromLine:"			84",
			toLine:"			97",
			content:"
			    })
			    @PostMapping()
			    @ResponseStatus(HttpStatus.CREATED)
			    @ApiException(CREATE_ACCESS_TOKEN_ERROR)
			    @OperatorLog(auditType = AuditType.TOKEN_CREATE)
			    public Result<AccessToken> createToken(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                           @RequestParam(value = "userId") int userId,
			                                           @RequestParam(value = "expireTime") String expireTime,
			                                           @RequestParam(value = "token", required = false) String token) {
			
			        AccessToken accessToken = accessTokenService.createToken(loginUser, userId, expireTime, token);
			        return Result.success(accessToken);
			    }
						
",
,
			fromLine:"			105",
			toLine:"			117",
			content:"
			     */
			    @Parameter(hidden = true)
			    @PostMapping(value = "/generate")
			    @ResponseStatus(HttpStatus.CREATED)
			    @ApiException(GENERATE_TOKEN_ERROR)
			    public Result<String> generateToken(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                        @RequestParam(value = "userId") int userId,
			                                        @RequestParam(value = "expireTime") String expireTime) {
			        String token = accessTokenService.generateToken(loginUser, userId, expireTime);
			        return Result.success(token);
			    }
			
			    /**			
",
,
			fromLine:"			130",
			toLine:"			143",
			content:"
			            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class), example = "20")
			    })
			    @GetMapping()
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(QUERY_ACCESSTOKEN_LIST_PAGING_ERROR)
			    public Result<PageInfo<AccessToken>> queryAccessTokenList(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                              @RequestParam("pageNo") Integer pageNo,
			                                                              @RequestParam(value = "searchVal", required = false) String searchVal,
			                                                              @RequestParam("pageSize") Integer pageSize) {
			
			        checkPageParams(pageNo, pageSize);
			        searchVal = ParameterUtils.handleEscapes(searchVal);
			        PageInfo<AccessToken> accessTokenPageInfo =
			                accessTokenService.queryAccessTokenList(loginUser, searchVal, pageNo, pageSize);			
",
,
			fromLine:"			202",
			toLine:"			216",
			content:"
			    })
			    @PutMapping(value = "/{id}")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(UPDATE_ACCESS_TOKEN_ERROR)
			    @OperatorLog(auditType = AuditType.TOKEN_UPDATE)
			    public Result<AccessToken> updateToken(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                           @PathVariable(value = "id") int id,
			                                           @RequestParam(value = "userId") int userId,
			                                           @RequestParam(value = "expireTime") String expireTime,
			                                           @RequestParam(value = "token", required = false) String token) {
			
			        AccessToken accessToken = accessTokenService.updateToken(loginUser, id, userId, expireTime, token);
			        return Result.success(accessToken);
			    }
						
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/AccessTokenService.java:
		[
			fromLine:"			17",
			toLine:"			25",
			content:"
			
			package org.apache.dolphinscheduler.api.service;
			
			import org.apache.dolphinscheduler.api.utils.PageInfo;
			import org.apache.dolphinscheduler.dao.entity.AccessToken;
			import org.apache.dolphinscheduler.dao.entity.User;
			
			import java.util.List;
						
",
,
			fromLine:"			35",
			toLine:"			45",
			content:"
			     * @param searchVal search value
			     * @param pageNo page number
			     * @param pageSize page size
			     * @return token list for page number and page size
			     */
			    PageInfo<AccessToken> queryAccessTokenList(User loginUser, String searchVal, Integer pageNo, Integer pageSize);
			
			    /**
			     * query access token for specified user
			     *
			     * @param loginUser login user			
",
,
			fromLine:"			54",
			toLine:"			73",
			content:"
			     * @param userId token for user
			     * @param expireTime token expire time
			     * @param token token string (if it is absent, it will be automatically generated)
			     * @return create result code
			     */
			    AccessToken createToken(User loginUser, int userId, String expireTime, String token);
			
			    /**
			     * generate token
			     *
			     * @param userId token for user
			     * @param expireTime token expire time
			     * @return token string
			     */
			    String generateToken(User loginUser, int userId, String expireTime);
			
			    /**
			     * delete access token
			     *
			     * @param loginUser login user			
",
,
			fromLine:"			83",
			toLine:"			93",
			content:"
			     * @param userId token for user
			     * @param expireTime token expire time
			     * @param token token string (if it is absent, it will be automatically generated)
			     * @return updated access token entity
			     */
			    AccessToken updateToken(User loginUser, int id, int userId, String expireTime, String token);
			}
						
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/EnvironmentDto.java:
		[
			fromLine:"			17",
			toLine:"			61",
			content:"
			
			package org.apache.dolphinscheduler.api.dto;
			
			import java.util.Date;
			import java.util.List;
			
			import lombok.Data;
			
			@Data
			public class EnvironmentDto {
			
			    private Integer id;
			
			    /**
			     * environment code
			     */
			    private Long code;
			
			    /**
			     * environment name
			     */
			    private String name;
			
			    /**
			     * config content
			     */
			    private String config;
			
			    private String description;
			
			    private List<String> workerGroups;
			
			    /**
			     * operator user id
			     */
			    private Integer operator;
			
			    private Date createTime;
			
			    private Date updateTime;
			}
						
",
,

		],
		dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/AccessToken.java:
		[
			fromLine:"			17",
			toLine:"			29",
			content:"
			
			package org.apache.dolphinscheduler.dao.entity;
			
			import java.util.Date;
			import java.util.Objects;
			
			import lombok.Data;
			
			import com.baomidou.mybatisplus.annotation.IdType;
			import com.baomidou.mybatisplus.annotation.TableField;
			import com.baomidou.mybatisplus.annotation.TableId;
			import com.baomidou.mybatisplus.annotation.TableName;
						
",
,
			fromLine:"			33",
			toLine:"			70",
			content:"
			
			    /**
			     * primary key
			     */
			    @TableId(value = "id", type = IdType.AUTO)
			    private Integer id;
			    /**
			     * user_id
			     */
			    @TableField(value = "user_id")
			    private int userId;
			    /**
			     * token
			     */
			    @TableField(value = "token")
			    private String token;
			    /**
			     * expire_time
			     */
			    @TableField(value = "expire_time")
			    private Date expireTime;
			    /**
			     * create_time
			     */
			    @TableField(value = "create_time")
			    private Date createTime;
			    /**
			     * update_time
			     */
			    @TableField(value = "update_time")
			    private Date updateTime;
			    @TableField(exist = false)
			    private String userName;
			
			    @Override
			    public boolean equals(Object o) {
			        if (this == o) {
			            return true;			
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AuditLogController.java:
		[
			fromLine:"			17",
			toLine:"			48",
			content:"
			
			package org.apache.dolphinscheduler.api.controller;
			
			import static org.apache.dolphinscheduler.api.enums.Status.QUERY_AUDIT_LOG_LIST_PAGING;
			
			import org.apache.dolphinscheduler.api.dto.AuditDto;
			import org.apache.dolphinscheduler.api.dto.auditLog.AuditModelTypeDto;
			import org.apache.dolphinscheduler.api.dto.auditLog.AuditOperationTypeDto;
			import org.apache.dolphinscheduler.api.exceptions.ApiException;
			import org.apache.dolphinscheduler.api.service.AuditService;
			import org.apache.dolphinscheduler.api.utils.PageInfo;
			import org.apache.dolphinscheduler.api.utils.Result;
			import org.apache.dolphinscheduler.common.constants.Constants;
			import org.apache.dolphinscheduler.dao.entity.User;
			
			import java.util.List;
			
			import org.springframework.beans.factory.annotation.Autowired;
			import org.springframework.http.HttpStatus;
			import org.springframework.web.bind.annotation.GetMapping;
			import org.springframework.web.bind.annotation.RequestAttribute;
			import org.springframework.web.bind.annotation.RequestMapping;
			import org.springframework.web.bind.annotation.RequestParam;
			import org.springframework.web.bind.annotation.ResponseStatus;
			import org.springframework.web.bind.annotation.RestController;
			
			import io.swagger.v3.oas.annotations.Operation;
			import io.swagger.v3.oas.annotations.Parameter;
			import io.swagger.v3.oas.annotations.Parameters;
			import io.swagger.v3.oas.annotations.media.Schema;
			import io.swagger.v3.oas.annotations.tags.Tag;
						
",
,
			fromLine:"			80",
			toLine:"			98",
			content:"
			            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "20"))
			    })
			    @GetMapping(value = "/audit-log-list")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(QUERY_AUDIT_LOG_LIST_PAGING)
			    public Result<PageInfo<AuditDto>> queryAuditLogListPaging(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                              @RequestParam("pageNo") Integer pageNo,
			                                                              @RequestParam("pageSize") Integer pageSize,
			                                                              @RequestParam(value = "modelTypes", required = false) String modelTypes,
			                                                              @RequestParam(value = "operationTypes", required = false) String operationTypes,
			                                                              @RequestParam(value = "startDate", required = false) String startDate,
			                                                              @RequestParam(value = "endDate", required = false) String endDate,
			                                                              @RequestParam(value = "userName", required = false) String userName,
			                                                              @RequestParam(value = "modelName", required = false) String modelName) {
			        checkPageParams(pageNo, pageSize);
			        PageInfo<AuditDto> auditDtoPageInfo = auditService.queryLogListPaging(
			                modelTypes,
			                operationTypes,
			                startDate,			
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkflowInstanceController.java:
		[
			fromLine:"			17",
			toLine:"			64",
			content:"
			
			package org.apache.dolphinscheduler.api.controller;
			
			import static org.apache.dolphinscheduler.api.enums.Status.QUERY_WORKFLOW_INSTANCE_LIST_PAGING_ERROR;
			
			import org.apache.dolphinscheduler.api.audit.OperatorLog;
			import org.apache.dolphinscheduler.api.audit.enums.AuditType;
			import org.apache.dolphinscheduler.api.dto.DynamicSubWorkflowDto;
			import org.apache.dolphinscheduler.api.enums.Status;
			import org.apache.dolphinscheduler.api.exceptions.ApiException;
			import org.apache.dolphinscheduler.api.service.WorkflowInstanceService;
			import org.apache.dolphinscheduler.api.utils.Result;
			import org.apache.dolphinscheduler.common.constants.Constants;
			import org.apache.dolphinscheduler.common.enums.WorkflowExecutionStatus;
			import org.apache.dolphinscheduler.dao.entity.User;
			import org.apache.dolphinscheduler.dao.entity.WorkflowInstance;
			import org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils;
			
			import org.apache.commons.lang3.StringUtils;
			
			import java.io.IOException;
			import java.text.MessageFormat;
			import java.util.ArrayList;
			import java.util.HashMap;
			import java.util.List;
			import java.util.Map;
			
			import lombok.extern.slf4j.Slf4j;
			
			import org.springframework.beans.factory.annotation.Autowired;
			import org.springframework.http.HttpStatus;
			import org.springframework.web.bind.annotation.DeleteMapping;
			import org.springframework.web.bind.annotation.GetMapping;
			import org.springframework.web.bind.annotation.PathVariable;
			import org.springframework.web.bind.annotation.PostMapping;
			import org.springframework.web.bind.annotation.PutMapping;
			import org.springframework.web.bind.annotation.RequestAttribute;
			import org.springframework.web.bind.annotation.RequestMapping;
			import org.springframework.web.bind.annotation.RequestParam;
			import org.springframework.web.bind.annotation.ResponseStatus;
			import org.springframework.web.bind.annotation.RestController;
			
			import io.swagger.v3.oas.annotations.Operation;
			import io.swagger.v3.oas.annotations.Parameter;
			import io.swagger.v3.oas.annotations.Parameters;
			import io.swagger.v3.oas.annotations.media.Schema;
			import io.swagger.v3.oas.annotations.tags.Tag;
						
",
,
			fromLine:"			103",
			toLine:"			124",
			content:"
			            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "10"))
			    })
			    @GetMapping()
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_LIST_PAGING_ERROR)
			    public Result queryWorkflowInstanceList(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                            @RequestParam(value = "workflowDefinitionCode", required = false, defaultValue = "0") long workflowDefinitionCode,
			                                            @RequestParam(value = "searchVal", required = false) String searchVal,
			                                            @RequestParam(value = "executorName", required = false) String executorName,
			                                            @RequestParam(value = "stateType", required = false) WorkflowExecutionStatus stateType,
			                                            @RequestParam(value = "host", required = false) String host,
			                                            @RequestParam(value = "startDate", required = false) String startTime,
			                                            @RequestParam(value = "endDate", required = false) String endTime,
			                                            @RequestParam(value = "otherParamsJson", required = false) String otherParamsJson,
			                                            @RequestParam("pageNo") Integer pageNo,
			                                            @RequestParam("pageSize") Integer pageSize) {
			
			        checkPageParams(pageNo, pageSize);
			        searchVal = ParameterUtils.handleEscapes(searchVal);
			        return workflowInstanceService.queryWorkflowInstanceList(loginUser, projectCode, workflowDefinitionCode,
			                startTime,			
",
,
			fromLine:"			139",
			toLine:"			151",
			content:"
			            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
			    })
			    @GetMapping(value = "/{id}/tasks")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_TASK_LIST_BY_WORKFLOW_INSTANCE_ID_ERROR)
			    public Result queryTaskListByWorkflowInstanceId(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                    @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                                    @PathVariable("id") Integer id) throws IOException {
			        Map<String, Object> result =
			                workflowInstanceService.queryTaskListByWorkflowInstanceId(loginUser, projectCode, id);
			        return returnDataList(result);
			    }
						
",
,
			fromLine:"			175",
			toLine:"			194",
			content:"
			    })
			    @PutMapping(value = "/{id}")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.UPDATE_WORKFLOW_INSTANCE_ERROR)
			    @OperatorLog(auditType = AuditType.WORKFLOW_INSTANCE_UPDATE)
			    public Result updateWorkflowInstance(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                         @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                         @RequestParam(value = "taskRelationJson", required = true) String taskRelationJson,
			                                         @RequestParam(value = "taskDefinitionJson", required = true) String taskDefinitionJson,
			                                         @PathVariable(value = "id") Integer id,
			                                         @RequestParam(value = "scheduleTime", required = false) String scheduleTime,
			                                         @RequestParam(value = "syncDefine", required = true) Boolean syncDefine,
			                                         @RequestParam(value = "globalParams", required = false, defaultValue = "[]") String globalParams,
			                                         @RequestParam(value = "locations", required = false) String locations,
			                                         @RequestParam(value = "timeout", required = false, defaultValue = "0") int timeout) {
			        Map<String, Object> result = workflowInstanceService.updateWorkflowInstance(loginUser, projectCode, id,
			                taskRelationJson, taskDefinitionJson, scheduleTime, syncDefine, globalParams, locations, timeout);
			        return returnDataList(result);
			    }
						
",
,
			fromLine:"			205",
			toLine:"			217",
			content:"
			            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
			    })
			    @GetMapping(value = "/{id}")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_BY_ID_ERROR)
			    public Result queryWorkflowInstanceById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                            @PathVariable("id") Integer id) {
			        Map<String, Object> result = workflowInstanceService.queryWorkflowInstanceById(loginUser, projectCode, id);
			        return returnDataList(result);
			    }
			
			    /**			
",
,
			fromLine:"			231",
			toLine:"			245",
			content:"
			            @Parameter(name = "endTime", description = "WORKFLOW_INSTANCE_END_TIME", required = true, schema = @Schema(implementation = String.class)),
			    })
			    @GetMapping(value = "/top-n")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_BY_ID_ERROR)
			    public Result<WorkflowInstance> queryTopNLongestRunningWorkflowInstance(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                                            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                                                            @RequestParam("size") Integer size,
			                                                                            @RequestParam(value = "startTime", required = true) String startTime,
			                                                                            @RequestParam(value = "endTime", required = true) String endTime) {
			        Map<String, Object> result = workflowInstanceService.queryTopNLongestRunningWorkflowInstance(loginUser,
			                projectCode, size, startTime, endTime);
			        return returnDataList(result);
			    }
						
",
,
			fromLine:"			258",
			toLine:"			270",
			content:"
			    })
			    @DeleteMapping(value = "/{id}")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.DELETE_WORKFLOW_INSTANCE_BY_ID_ERROR)
			    @OperatorLog(auditType = AuditType.WORKFLOW_INSTANCE_DELETE)
			    public Result<Void> deleteWorkflowInstanceById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                   @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                                   @PathVariable("id") Integer id) {
			        workflowInstanceService.deleteWorkflowInstanceById(loginUser, id);
			        return Result.success();
			    }
			
			    /**			
",
,
			fromLine:"			280",
			toLine:"			292",
			content:"
			            @Parameter(name = "taskCode", description = "TASK_CODE", required = true, schema = @Schema(implementation = long.class, example = "100"))
			    })
			    @GetMapping(value = "/query-sub-by-parent")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_SUB_WORKFLOW_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR)
			    public Result querySubWorkflowInstanceByTaskId(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                   @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                                   @RequestParam("taskId") Integer taskId) {
			        Map<String, Object> result =
			                workflowInstanceService.querySubWorkflowInstanceByTaskId(loginUser, projectCode, taskId);
			        return returnDataList(result);
			    }
						
",
,
			fromLine:"			303",
			toLine:"			315",
			content:"
			            @Parameter(name = "subId", description = "SUB_WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
			    })
			    @GetMapping(value = "/query-parent-by-sub")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_PARENT_WORKFLOW_INSTANCE_DETAIL_INFO_BY_SUB_WORKFLOW_INSTANCE_ID_ERROR)
			    public Result queryParentInstanceBySubId(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                             @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                             @RequestParam("subId") Integer subId) {
			        Map<String, Object> result = workflowInstanceService.queryParentInstanceBySubId(loginUser, projectCode, subId);
			        return returnDataList(result);
			    }
			
			    /**			
",
,
			fromLine:"			345",
			toLine:"			357",
			content:"
			            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
			    })
			    @GetMapping(value = "/{id}/view-variables")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_ALL_VARIABLES_ERROR)
			    public Result viewVariables(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                                @PathVariable("id") Integer id) {
			        Map<String, Object> result = workflowInstanceService.viewVariables(projectCode, id);
			        return returnDataList(result);
			    }
			
			    /**			
",
,
			fromLine:"			367",
			toLine:"			379",
			content:"
			            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
			    })
			    @GetMapping(value = "/{id}/view-gantt")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.ENCAPSULATION_WORKFLOW_INSTANCE_GANTT_STRUCTURE_ERROR)
			    public Result viewTree(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                           @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
			                           @PathVariable("id") Integer id) throws Exception {
			        Map<String, Object> result = workflowInstanceService.viewGantt(projectCode, id);
			        return returnDataList(result);
			    }
			
			    /**			
",
,
			fromLine:"			392",
			toLine:"			404",
			content:"
			    })
			    @PostMapping(value = "/batch-delete")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(Status.BATCH_DELETE_WORKFLOW_INSTANCE_BY_IDS_ERROR)
			    @OperatorLog(auditType = AuditType.WORKFLOW_INSTANCE_BATCH_DELETE)
			    public Result batchDeleteWorkflowInstanceByIds(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                   @PathVariable long projectCode,
			                                                   @RequestParam("workflowInstanceIds") String workflowInstanceIds) {
			        // task queue
			        Map<String, Object> result = new HashMap<>();
			        List<String> deleteFailedIdList = new ArrayList<>();
			        if (!StringUtils.isEmpty(workflowInstanceIds)) {
			            String[] workflowInstanceIdArray = workflowInstanceIds.split(Constants.COMMA);			
",
,
			fromLine:"			432",
			toLine:"			444",
			content:"
			            @Parameter(name = "triggerCode", description = "TRIGGER_CODE", required = true, schema = @Schema(implementation = Long.class))
			    })
			    @GetMapping("/trigger")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(QUERY_WORKFLOW_INSTANCE_LIST_PAGING_ERROR)
			    public Result queryWorkflowInstancesByTriggerCode(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                      @PathVariable long projectCode,
			                                                      @RequestParam(value = "triggerCode") Long triggerCode) {
			        Map<String, Object> result = workflowInstanceService.queryByTriggerCode(loginUser, projectCode, triggerCode);
			        return returnDataList(result);
			    }
			}
						
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/WorkflowInstanceService.java:
		[
			fromLine:"			17",
			toLine:"			58",
			content:"
			
			package org.apache.dolphinscheduler.api.service;
			
			import org.apache.dolphinscheduler.api.dto.DynamicSubWorkflowDto;
			import org.apache.dolphinscheduler.api.dto.workflowInstance.WorkflowInstanceQueryRequest;
			import org.apache.dolphinscheduler.api.utils.PageInfo;
			import org.apache.dolphinscheduler.api.utils.Result;
			import org.apache.dolphinscheduler.common.enums.WorkflowExecutionStatus;
			import org.apache.dolphinscheduler.dao.entity.User;
			import org.apache.dolphinscheduler.dao.entity.WorkflowInstance;
			
			import java.io.IOException;
			import java.util.List;
			import java.util.Map;
			
			public interface WorkflowInstanceService {
			
			    /**
			     * return top n SUCCESS workflow instance order by running time which started between startTime and endTime
			     */
			    Map<String, Object> queryTopNLongestRunningWorkflowInstance(User loginUser,
			                                                                long projectCode,
			                                                                int size,
			                                                                String startTime,
			                                                                String endTime);
			
			    /**
			     * query workflow instance by id
			     *
			     * @param loginUser   login user
			     * @param projectCode project code
			     * @param workflowInstanceId   workflow instance id
			     * @return workflow instance detail
			     */
			    Map<String, Object> queryWorkflowInstanceById(User loginUser,
			                                                  long projectCode,
			                                                  Integer workflowInstanceId);
			
			    WorkflowInstance queryByWorkflowInstanceIdThrowExceptionIfNotFound(Integer workflowInstanceId);
			
			    /**
			     * query workflow instance by id			
",
,
			fromLine:"			78",
			toLine:"			99",
			content:"
			     * @param startDate         start time
			     * @param endDate           end time
			     * @param otherParamsJson   otherParamsJson handle other params
			     * @return workflow instance list
			     */
			    Result<PageInfo<WorkflowInstance>> queryWorkflowInstanceList(User loginUser,
			                                                                 long projectCode,
			                                                                 long workflowDefinitionCode,
			                                                                 String startDate,
			                                                                 String endDate,
			                                                                 String searchVal,
			                                                                 String executorName,
			                                                                 WorkflowExecutionStatus stateType,
			                                                                 String host,
			                                                                 String otherParamsJson,
			                                                                 Integer pageNo,
			                                                                 Integer pageSize);
			
			    /**
			     * paging query workflow instance list, filtering according to project, workflow definition, time range, keyword, workflow status
			     *
			     * @param loginUser                    login user			
",
,
			fromLine:"			110",
			toLine:"			134",
			content:"
			     * @param projectCode project code
			     * @param workflowInstanceId   workflow instance id
			     * @return task list for the workflow instance
			     * @throws IOException io exception
			     */
			    Map<String, Object> queryTaskListByWorkflowInstanceId(User loginUser,
			                                                          long projectCode,
			                                                          Integer workflowInstanceId) throws IOException;
			
			    /**
			     * query sub workflow instance detail info by task id
			     *
			     * @param loginUser   login user
			     * @param projectCode project code
			     * @param taskId      task id
			     * @return sub workflow instance detail
			     */
			    Map<String, Object> querySubWorkflowInstanceByTaskId(User loginUser,
			                                                         long projectCode,
			                                                         Integer taskId);
			
			    List<DynamicSubWorkflowDto> queryDynamicSubWorkflowInstances(User loginUser,
			                                                                 Integer taskId);
			
			    /**			
",
,
			fromLine:"			144",
			toLine:"			175",
			content:"
			     * @param globalParams       global params
			     * @param locations          locations for nodes
			     * @param timeout            timeout
			     * @return update result code
			     */
			    Map<String, Object> updateWorkflowInstance(User loginUser,
			                                               long projectCode,
			                                               Integer workflowInstanceId,
			                                               String taskRelationJson,
			                                               String taskDefinitionJson,
			                                               String scheduleTime,
			                                               Boolean syncDefine,
			                                               String globalParams,
			                                               String locations,
			                                               int timeout);
			
			    /**
			     * query parent workflow instance detail info by sub workflow instance id
			     *
			     * @param loginUser   login user
			     * @param projectCode project code
			     * @param subId       sub workflow id
			     * @return parent instance detail
			     */
			    Map<String, Object> queryParentInstanceBySubId(User loginUser,
			                                                   long projectCode,
			                                                   Integer subId);
			
			    /**
			     * delete workflow instance by id, at the same time，delete task instance and their mapping relation data
			     *
			     * @param loginUser         login user			
",
,
			fromLine:"			214",
			toLine:"			226",
			content:"
			     * @param workflowDefinitionCode    workflowDefinitionCode
			     * @param workflowDefinitionVersion workflowDefinitionVersion
			     * @param states                    states array
			     * @return workflow instance list
			     */
			    List<WorkflowInstance> queryByWorkflowCodeVersionStatus(Long workflowDefinitionCode,
			                                                            int workflowDefinitionVersion,
			                                                            int[] states);
			
			    /**
			     * query workflow instance by workflowDefinitionCode
			     *
			     * @param workflowDefinitionCode workflowDefinitionCode			
",
,
			fromLine:"			236",
			toLine:"			246",
			content:"
			     * @param loginUser
			     * @param projectCode
			     * @param triggerCode
			     * @return
			     */
			    Map<String, Object> queryByTriggerCode(User loginUser, long projectCode, Long triggerCode);
			
			    void deleteWorkflowInstanceByWorkflowDefinitionCode(long workflowDefinitionCode);
			
			    void deleteWorkflowInstanceById(int workflowInstanceId);
						
",
,

		],
		dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java:
		[
			fromLine:"			17",
			toLine:"			61",
			content:"
			
			package org.apache.dolphinscheduler.api.controller;
			
			import static org.apache.dolphinscheduler.api.enums.Status.CREATE_ALERT_GROUP_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.DELETE_ALERT_GROUP_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.LIST_PAGING_ALERT_GROUP_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ALERT_GROUP_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ALL_ALERTGROUP_ERROR;
			import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_ALERT_GROUP_ERROR;
			
			import org.apache.dolphinscheduler.api.audit.OperatorLog;
			import org.apache.dolphinscheduler.api.audit.enums.AuditType;
			import org.apache.dolphinscheduler.api.enums.Status;
			import org.apache.dolphinscheduler.api.exceptions.ApiException;
			import org.apache.dolphinscheduler.api.service.AlertGroupService;
			import org.apache.dolphinscheduler.api.utils.PageInfo;
			import org.apache.dolphinscheduler.api.utils.Result;
			import org.apache.dolphinscheduler.common.constants.Constants;
			import org.apache.dolphinscheduler.dao.entity.AlertGroup;
			import org.apache.dolphinscheduler.dao.entity.User;
			import org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils;
			
			import java.util.List;
			
			import lombok.extern.slf4j.Slf4j;
			
			import org.springframework.beans.factory.annotation.Autowired;
			import org.springframework.http.HttpStatus;
			import org.springframework.web.bind.annotation.DeleteMapping;
			import org.springframework.web.bind.annotation.GetMapping;
			import org.springframework.web.bind.annotation.PathVariable;
			import org.springframework.web.bind.annotation.PostMapping;
			import org.springframework.web.bind.annotation.PutMapping;
			import org.springframework.web.bind.annotation.RequestAttribute;
			import org.springframework.web.bind.annotation.RequestMapping;
			import org.springframework.web.bind.annotation.RequestParam;
			import org.springframework.web.bind.annotation.ResponseStatus;
			import org.springframework.web.bind.annotation.RestController;
			
			import io.swagger.v3.oas.annotations.Operation;
			import io.swagger.v3.oas.annotations.Parameter;
			import io.swagger.v3.oas.annotations.Parameters;
			import io.swagger.v3.oas.annotations.media.Schema;
			import io.swagger.v3.oas.annotations.tags.Tag;
						
",
,
			fromLine:"			87",
			toLine:"			100",
			content:"
			    })
			    @PostMapping()
			    @ResponseStatus(HttpStatus.CREATED)
			    @ApiException(CREATE_ALERT_GROUP_ERROR)
			    @OperatorLog(auditType = AuditType.ALARM_GROUP_CREATE)
			    public Result<AlertGroup> createAlertGroup(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                               @RequestParam(value = "groupName") String groupName,
			                                               @RequestParam(value = "description", required = false) String description,
			                                               @RequestParam(value = "alertInstanceIds") String alertInstanceIds) {
			        AlertGroup alertgroup = alertGroupService.createAlertGroup(loginUser, groupName, description, alertInstanceIds);
			        return Result.success(alertgroup);
			    }
			
			    /**			
",
,
			fromLine:"			129",
			toLine:"			142",
			content:"
			            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "20"))
			    })
			    @GetMapping()
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(LIST_PAGING_ALERT_GROUP_ERROR)
			    public Result<PageInfo<AlertGroup>> listPaging(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                   @RequestParam(value = "searchVal", required = false) String searchVal,
			                                                   @RequestParam("pageNo") Integer pageNo,
			                                                   @RequestParam("pageSize") Integer pageSize) {
			        checkPageParams(pageNo, pageSize);
			        searchVal = ParameterUtils.handleEscapes(searchVal);
			        PageInfo<AlertGroup> alertGroupPageInfo = alertGroupService.listPaging(loginUser, searchVal, pageNo, pageSize);
			        return Result.success(alertGroupPageInfo);
			    }			
",
,
			fromLine:"			181",
			toLine:"			195",
			content:"
			    })
			    @PutMapping(value = "/{id}")
			    @ResponseStatus(HttpStatus.OK)
			    @ApiException(UPDATE_ALERT_GROUP_ERROR)
			    @OperatorLog(auditType = AuditType.ALARM_GROUP_UPDATE)
			    public Result<AlertGroup> updateAlertGroupById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
			                                                   @PathVariable(value = "id") int id,
			                                                   @RequestParam(value = "groupName") String groupName,
			                                                   @RequestParam(value = "description", required = false) String description,
			                                                   @RequestParam(value = "alertInstanceIds") String alertInstanceIds) {
			        AlertGroup alertGroup =
			                alertGroupService.updateAlertGroupById(loginUser, id, groupName, description, alertInstanceIds);
			        return Result.success(alertGroup);
			    }
						
",
,

		],
		dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/EnvironmentWorkerGroupRelation.java:
		[
			fromLine:"			17",
			toLine:"			57",
			content:"
			
			package org.apache.dolphinscheduler.dao.entity;
			
			import java.util.Date;
			
			import lombok.Data;
			
			import com.baomidou.mybatisplus.annotation.IdType;
			import com.baomidou.mybatisplus.annotation.TableId;
			import com.baomidou.mybatisplus.annotation.TableName;
			
			@Data
			@TableName("t_ds_environment_worker_group_relation")
			public class EnvironmentWorkerGroupRelation {
			
			    @TableId(value = "id", type = IdType.AUTO)
			    private Integer id;
			
			    /**
			     * environment code
			     */
			    private Long environmentCode;
			
			    /**
			     * worker group id
			     */
			    private String workerGroup;
			
			    /**
			     * operator user id
			     */
			    private Integer operator;
			
			    private Date createTime;
			
			    private Date updateTime;
			}
						
",
,

		],
		dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/ProjectWorkerGroup.java:
		[
			fromLine:"			17",
			toLine:"			27",
			content:"
			
			package org.apache.dolphinscheduler.dao.entity;
			
			import java.util.Date;
			
			import lombok.Data;
			
			import com.baomidou.mybatisplus.annotation.IdType;
			import com.baomidou.mybatisplus.annotation.TableId;
			import com.baomidou.mybatisplus.annotation.TableName;
						
",
,
			fromLine:"			31",
			toLine:"			61",
			content:"
			
			    /**
			     * id
			     */
			    @TableId(value = "id", type = IdType.AUTO)
			    private Integer id;
			
			    /**
			     * project code
			     */
			    private Long projectCode;
			
			    /**
			     * worker group
			     */
			    private String workerGroup;
			
			    /**
			     * create time
			     */
			    private Date createTime;
			
			    /**
			     * update time
			     */
			    private Date updateTime;
			}
						
",
,

		],
	
}
	role:"
	user	
",
,

],
model:"
gpt-4-1106-preview
",
response_format:
{
	type:"
	json_object	
",

}
temperature:"0.9",
