messages:
[
	content:"
	
	I will provide you one or more Java code files .
	Find all data clumps in the respective files.
	
	
	
	## OUTPUT FORMAT
	Use the following JSON format for the output:
	
	{
	   "data_clumps":{
	        "unique_key":{
	            "key": "a unique key that should be created. It must be same as the key 'unique_key' in the 'data_clumps' object",
	            "from_file_path":"The path of the file where one part of the data clump is found",
	            "from_class_or_interface_key":"The fully qualified name of the class or interface where one part of the data clump is found",
	            "from_class_or_interface_name":"The name of the class or interface where one part of the data clump is found",
	            
	            "from_method_key":"The fully qualified name of the method where one part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	            "from_method_name":"The name of the method where one part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	
	            "to_file_path":"The path of the file where the  other part of the data clump is found",
	            "to_class_or_interface_key":"The fully qualified name of the class or interface where the  other part part of the data clump is found",
	            "to_class_or_interface_name":"The name of the class or interface where the  other  part of the data clump is found",
	            
	            "to_method_key":"The fully qualified name of the method where the  other part part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	            "to_method_name":"The name of the method where the  other  part of the data clump is found. It may be 'null' if the data clump on this part is not found in a method",
	            "data_clump_data":{
	                // for each data clump variable
	                "other_unique_key":{
	                    "key":"a unique key that should be created. It must be same as the key 'other_unique_key' in the 'data_clump_data' object",
	                    "name": "The name of the data clump variable that exists on the one part of the data clump",
	                    "type": "The type of the data clump variable that exists on the one part of the data clump",
	                    "displayedType": "The  type of the data clump variable, as it appears in the source code, that exists on the one part of the data clump",
	                    
	                    "position": {
	                        "startLine": "The line number of the  data clump variable on the one part of the data clump.This must be relative to the file",
	                        "startColumn": "The column number of the data clump variable on the one part of the data clump"
	                    },
	                    "to_variable":{
	                        "key":"a unique key that should be created.",
	                        "name": "The name of the data clump variable that exists on the other part of the data clump",
	                        "type": "The type of the data clump variable, as it appears in the source code, that exists on the other part of the data clump",
	                        "position": {
	                            "startLine": "The line number of the  data clump variable on the other part of the data clump. This must be relative to the file",
	                            "startColumn": "The column number of the data clump variable on the other part of the data clump",
	                        }
	                    }
	                }
	            }
	        }
	   }
	}
	
	## END OUTPUT FORMAT
		
",
	role:"
	system	
",
,
	content:"
	//dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/src/main/java/org/apache/dolphinscheduler/plugin/datasource/api/constants/DataSourceConstants.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.plugin.datasource.api.constants;
	
	import org.apache.dolphinscheduler.common.constants.DateConstants;
	
	import java.time.Duration;
	import java.util.Set;
	import java.util.regex.Pattern;
	
	import lombok.experimental.UtilityClass;
	
	import com.google.common.collect.Sets;
	
	@UtilityClass
	public class DataSourceConstants {
	
	    public static final String ORG_POSTGRESQL_DRIVER = "org.postgresql.Driver";
	    public static final String COM_MYSQL_CJ_JDBC_DRIVER = "com.mysql.cj.jdbc.Driver";
	    public static final String COM_MYSQL_JDBC_DRIVER = "com.mysql.jdbc.Driver";
	    public static final String ORG_APACHE_HIVE_JDBC_HIVE_DRIVER = "org.apache.hive.jdbc.HiveDriver";
	    public static final String COM_CLICKHOUSE_JDBC_DRIVER = "com.clickhouse.jdbc.ClickHouseDriver";
	    public static final String COM_DATABEND_JDBC_DRIVER = "com.databend.jdbc.DatabendDriver";
	    public static final String COM_ORACLE_JDBC_DRIVER = "oracle.jdbc.OracleDriver";
	    public static final String COM_SQLSERVER_JDBC_DRIVER = "com.microsoft.sqlserver.jdbc.SQLServerDriver";
	    public static final String COM_DB2_JDBC_DRIVER = "com.ibm.db2.jcc.DB2Driver";
	    public static final String COM_PRESTO_JDBC_DRIVER = "com.facebook.presto.jdbc.PrestoDriver";
	    public static final String COM_REDSHIFT_JDBC_DRIVER = "com.amazon.redshift.jdbc42.Driver";
	    public static final String COM_ATHENA_JDBC_DRIVER = "com.simba.athena.jdbc.Driver";
	    public static final String COM_TRINO_JDBC_DRIVER = "io.trino.jdbc.TrinoDriver";
	    public static final String COM_DAMENG_JDBC_DRIVER = "dm.jdbc.driver.DmDriver";
	    public static final String ORG_APACHE_KYUUBI_JDBC_DRIVER = "org.apache.kyuubi.jdbc.KyuubiHiveDriver";
	    public static final String COM_OCEANBASE_JDBC_DRIVER = "com.oceanbase.jdbc.Driver";
	    public static final String NET_SNOWFLAKE_JDBC_DRIVER = "net.snowflake.client.jdbc.SnowflakeDriver";
	    public static final String COM_VERTICA_JDBC_DRIVER = "com.vertica.jdbc.Driver";
	    public static final String COM_HANA_DB_JDBC_DRIVER = "com.sap.db.jdbc.Driver";
	
	    public static final String JDBC_MYSQL = "jdbc:mysql://";
	    public static final String JDBC_MYSQL_LOADBALANCE = "jdbc:mysql:loadbalance://";
	    public static final String JDBC_POSTGRESQL = "jdbc:postgresql://";
	    public static final String JDBC_HIVE_2 = "jdbc:hive2://";
	    public static final String JDBC_KYUUBI = "jdbc:kyuubi://";
	    public static final String JDBC_CLICKHOUSE = "jdbc:clickhouse://";
	    public static final String JDBC_DATABEND = "jdbc:databend://";
	    public static final String JDBC_ORACLE_SID = "jdbc:oracle:thin:@";
	    public static final String JDBC_ORACLE_SERVICE_NAME = "jdbc:oracle:thin:@//";
	    public static final String JDBC_SQLSERVER = "jdbc:sqlserver://";
	    public static final String JDBC_DB2 = "jdbc:db2://";
	    public static final String JDBC_PRESTO = "jdbc:presto://";
	    public static final String JDBC_REDSHIFT = "jdbc:redshift://";
	    public static final String JDBC_REDSHIFT_IAM = "jdbc:redshift:iam://";
	    public static final String JDBC_ATHENA = "jdbc:awsathena://";
	    public static final String JDBC_TRINO = "jdbc:trino://";
	    public static final String JDBC_DAMENG = "jdbc:dm://";
	    public static final String JDBC_OCEANBASE = "jdbc:oceanbase://";
	    public static final String JDBC_SNOWFLAKE = "jdbc:snowflake://";
	    public static final String JDBC_VERTICA = "jdbc:vertica://";
	    public static final String JDBC_HANA = "jdbc:sap://";
	
	    public static final String POSTGRESQL_VALIDATION_QUERY = "select version()";
	    public static final String MYSQL_VALIDATION_QUERY = "select 1";
	    public static final String HIVE_VALIDATION_QUERY = "select 1";
	    public static final String CLICKHOUSE_VALIDATION_QUERY = "select 1";
	    public static final String DATABEND_VALIDATION_QUERY = "select 1";
	    public static final String ORACLE_VALIDATION_QUERY = "select 1 from dual";
	    public static final String SQLSERVER_VALIDATION_QUERY = "select 1";
	    public static final String DB2_VALIDATION_QUERY = "select 1 from sysibm.sysdummy1";
	    public static final String PRESTO_VALIDATION_QUERY = "select 1";
	    public static final String REDHIFT_VALIDATION_QUERY = "select 1";
	    public static final String ATHENA_VALIDATION_QUERY = "select 1";
	    public static final String TRINO_VALIDATION_QUERY = "select 1";
	    public static final String DAMENG_VALIDATION_QUERY = "select 1";
	    public static final String SNOWFLAKE_VALIDATION_QUERY = "select 1";
	
	    public static final String KYUUBI_VALIDATION_QUERY = "select 1";
	    public static final String VERTICA_VALIDATION_QUERY = "select 1";
	
	    public static final String HANA_VALIDATION_QUERY = "select 1 from DUMMY";
	
	    public static final String SPRING_DATASOURCE_MIN_IDLE = "spring.datasource.minIdle";
	
	    public static final String SPRING_DATASOURCE_MAX_ACTIVE = "spring.datasource.maxActive";
	
	    public static final String SUPPORT_HIVE_ONE_SESSION = "support.hive.oneSession";
	    /**
	     * QUESTION ?
	     */
	    public static final String QUESTION = "?";
	
	    /**
	     * comma ,
	     */
	    public static final String COMMA = ",";
	
	    /**
	     * hyphen
	     */
	    public static final String HYPHEN = "-";
	
	    /**
	     * slash /
	     */
	    public static final String SLASH = "/";
	
	    /**
	     * COLON :
	     */
	    public static final String COLON = ":";
	
	    /**
	     * SPACE " "
	     */
	    public static final String SPACE = " ";
	
	    /**
	     * SINGLE_SLASH /
	     */
	    public static final String SINGLE_SLASH = "/";
	
	    /**
	     * DOUBLE_SLASH //
	     */
	    public static final String DOUBLE_SLASH = "//";
	
	    /**
	     * SINGLE_QUOTES "'"
	     */
	    public static final String SINGLE_QUOTES = "'";
	    /**
	     * DOUBLE_QUOTES "\""
	     */
	    public static final String DOUBLE_QUOTES = "\"";
	
	    /**
	     * SEMICOLON ;
	     */
	    public static final String SEMICOLON = ";";
	
	    /**
	     * EQUAL SIGN
	     */
	    public static final String EQUAL_SIGN = "=";
	    /**
	     * AT SIGN
	     */
	    public static final String AT_SIGN = "@";
	    /**
	     * UNDERLINE
	     */
	    public static final String UNDERLINE = "_";
	
	    /**
	     * sleep time
	     */
	    public static final int SLEEP_TIME_MILLIS = 1000;
	
	    /**
	     * exit code failure
	     */
	    public static final int EXIT_CODE_FAILURE = -1;
	
	    /**
	     * exit code success
	     */
	    public static final int EXIT_CODE_SUCCESS = 0;
	    /**
	     * running code
	     */
	    public static final int RUNNING_CODE = 1;
	
	    public static final String SH = "sh";
	
	    /**
	     * log flush interval?output when reach the interval
	     */
	    public static final int DEFAULT_LOG_FLUSH_INTERVAL = 1000;
	
	    /**
	     * pstree, get pud and sub pid
	     */
	    public static final String PSTREE = "pstree";
	
	    public static final String RWXR_XR_X = "rwxr-xr-x";
	
	    /**
	     * date format of yyyyMMddHHmmss
	     */
	    public static final String PARAMETER_FORMAT_TIME = "yyyyMMddHHmmss";
	
	    /**
	     * new
	     * schedule time
	     */
	    public static final String PARAMETER_SHECDULE_TIME = "schedule.time";
	
	    /**
	     * system date(yyyyMMddHHmmss)
	     */
	    public static final String PARAMETER_DATETIME = DateConstants.PARAMETER_DATETIME;
	
	    /**
	     * system date(yyyymmdd) today
	     */
	    public static final String PARAMETER_CURRENT_DATE = DateConstants.PARAMETER_CURRENT_DATE;
	
	    /**
	     * system date(yyyymmdd) yesterday
	     */
	    public static final String PARAMETER_BUSINESS_DATE = DateConstants.PARAMETER_BUSINESS_DATE;
	
	    /**
	     * the absolute path of current executing task
	     */
	    public static final String PARAMETER_TASK_EXECUTE_PATH = "system.task.execute.path";
	
	    /**
	     * the instance id of current task
	     */
	    public static final String PARAMETER_TASK_INSTANCE_ID = "system.task.instance.id";
	
	    /**
	     * the definition code of current task
	     */
	    public static final String PARAMETER_TASK_DEFINITION_CODE = "system.task.definition.code";
	
	    /**
	     * the definition name of current task
	     */
	    public static final String PARAMETER_TASK_DEFINITION_NAME = "system.task.definition.name";
	
	    /**
	     * the instance id of the workflow to which current task belongs
	     */
	    public static final String PARAMETER_WORKFLOW_INSTANCE_ID = "system.workflow.instance.id";
	
	    /**
	     * the definition code of the workflow to which current task belongs
	     */
	    public static final String PARAMETER_WORKFLOW_DEFINITION_CODE = "system.workflow.definition.code";
	
	    /**
	     * the definition name of the workflow to which current task belongs
	     */
	    public static final String PARAMETER_WORKFLOW_DEFINITION_NAME = "system.workflow.definition.name";
	
	    /**
	     * the code of the project to which current task belongs
	     */
	    public static final String PARAMETER_PROJECT_CODE = "system.project.code";
	
	    /**
	     * the name of the project to which current task belongs
	     */
	    public static final String PARAMETER_PROJECT_NAME = "system.project.name";
	    /**
	     * month_begin
	     */
	    public static final String MONTH_BEGIN = "month_begin";
	    /**
	     * add_months
	     */
	    public static final String ADD_MONTHS = "add_months";
	    /**
	     * month_end
	     */
	    public static final String MONTH_END = "month_end";
	    /**
	     * week_begin
	     */
	    public static final String WEEK_BEGIN = "week_begin";
	    /**
	     * week_end
	     */
	    public static final String WEEK_END = "week_end";
	    /**
	     * this_day
	     */
	    public static final String THIS_DAY = "this_day";
	    /**
	     * last_day
	     */
	    public static final String LAST_DAY = "last_day";
	
	    /**
	     * month_first_day
	     */
	    public static final String MONTH_FIRST_DAY = "month_first_day";
	
	    /**
	     * month_last_day
	     */
	    public static final String MONTH_LAST_DAY = "month_last_day";
	
	    /**
	     * week_first_day
	     */
	    public static final String WEEK_FIRST_DAY = "week_first_day";
	
	    /**
	     * week_last_day
	     */
	    public static final String WEEK_LAST_DAY = "week_last_day";
	
	    /**
	     * year_week
	     */
	    public static final String YEAR_WEEK = "year_week";
	    /**
	     * timestamp
	     */
	    public static final String TIMESTAMP = "timestamp";
	    public static final char SUBTRACT_CHAR = '-';
	    public static final char ADD_CHAR = '+';
	    public static final char MULTIPLY_CHAR = '*';
	    public static final char DIVISION_CHAR = '/';
	    public static final char LEFT_BRACE_CHAR = '(';
	    public static final char RIGHT_BRACE_CHAR = ')';
	    public static final String ADD_STRING = "+";
	    public static final String MULTIPLY_STRING = "*";
	    public static final String DIVISION_STRING = "/";
	    public static final String LEFT_BRACE_STRING = "(";
	    public static final char P = 'P';
	    public static final char N = 'N';
	    public static final String SUBTRACT_STRING = "-";
	    public static final String LOCAL_PARAMS_LIST = "localParamsList";
	    public static final String TASK_TYPE = "taskType";
	    public static final String QUEUE = "queue";
	    /**
	     * default display rows
	     */
	    public static final int DEFAULT_DISPLAY_ROWS = 10;
	
	    /**
	     * jar
	     */
	    public static final String JAR = "jar";
	
	    /**
	     * hadoop
	     */
	    public static final String HADOOP = "hadoop";
	
	    /**
	     * -D <property>=<value>
	     */
	    public static final String D = "-D";
	
	    /**
	     * datasource encryption salt
	     */
	    public static final String DATASOURCE_ENCRYPTION_SALT_DEFAULT = "!@#$%^&*";
	    public static final String DATASOURCE_ENCRYPTION_ENABLE = "datasource.encryption.enable";
	    public static final String DATASOURCE_ENCRYPTION_SALT = "datasource.encryption.salt";
	
	    /**
	     * kerberos
	     */
	    public static final String KERBEROS = "kerberos";
	
	    /**
	     * kerberos expire time
	     */
	    public static final String KERBEROS_EXPIRE_TIME = "kerberos.expire.time";
	
	    /**
	     * java.security.krb5.conf
	     */
	    public static final String JAVA_SECURITY_KRB5_CONF = "java.security.krb5.conf";
	
	    /**
	     * java.security.krb5.conf.path
	     */
	    public static final String JAVA_SECURITY_KRB5_CONF_PATH = "java.security.krb5.conf.path";
	
	    /**
	     * loginUserFromKeytab user
	     */
	    public static final String LOGIN_USER_KEY_TAB_USERNAME = "login.user.keytab.username";
	
	    /**
	     * loginUserFromKeytab path
	     */
	    public static final String LOGIN_USER_KEY_TAB_PATH = "login.user.keytab.path";
	
	    /**
	     * hadoop.security.authentication
	     */
	    public static final String HADOOP_SECURITY_AUTHENTICATION = "hadoop.security.authentication";
	
	    /**
	     * hadoop.security.authentication
	     */
	    public static final String HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE =
	            "hadoop.security.authentication.startup.state";
	
	    /**
	     * hdfs/s3 configuration
	     * resource.storage.upload.base.path
	     */
	    public static final String RESOURCE_UPLOAD_PATH = "resource.storage.upload.base.path";
	
	    /**
	     * data.quality.jar.dir
	     */
	    public static final String DATA_QUALITY_JAR_DIR = "data-quality.jar.dir";
	
	    public static final String TASK_TYPE_DATA_QUALITY = "DATA_QUALITY";
	
	    public static final Set<String> TASK_TYPE_SET_K8S = Sets.newHashSet("K8S", "KUBEFLOW");
	
	    /**
	     * azure config
	     */
	    public static final String AZURE_CLIENT_ID = "resource.azure.client.id";
	    public static final String AZURE_CLIENT_SECRET = "resource.azure.client.secret";
	    public static final String AZURE_ACCESS_SUB_ID = "resource.azure.subId";
	    public static final String AZURE_SECRET_TENANT_ID = "resource.azure.tenant.id";
	    public static final String QUERY_INTERVAL = "resource.query.interval";
	
	    /**
	     * use for k8s task
	     */
	    public static final String API_VERSION = "batch/v1";
	    public static final String RESTART_POLICY = "Never";
	    public static final String MEMORY = "memory";
	    public static final String CPU = "cpu";
	    public static final String LAYER_LABEL = "k8s.cn/layer";
	    public static final String LAYER_LABEL_VALUE = "batch";
	    public static final String NAME_LABEL = "k8s.cn/name";
	    public static final String TASK_INSTANCE_ID = "taskInstanceId";
	    public static final String MI = "Mi";
	    public static final int JOB_TTL_SECONDS = 300;
	    public static final int LOG_LINES = 500;
	    public static final String NAMESPACE_NAME = "name";
	    public static final String CLUSTER = "cluster";
	
	    /**
	     * spark / flink on k8s label name
	     */
	    public static final String UNIQUE_LABEL_NAME = "dolphinscheduler-label";
	
	    /**
	     * conda config used by jupyter task plugin
	     */
	    public static final String CONDA_PATH = "conda.path";
	
	    // Loop task constants
	    public static final Duration DEFAULT_LOOP_STATUS_INTERVAL = Duration.ofSeconds(5L);
	
	    /**
	     * sql params regex
	     */
	    public static final String GROUP_NAME1 = "paramName1";
	    public static final String GROUP_NAME2 = "paramName2";
	    public static final String SQL_PARAMS_REGEX =
	            String.format("['\"]\\$\\{(?<%s>.*?)}['\"]|\\$\\{(?<%s>.*?)}", GROUP_NAME1, GROUP_NAME2);
	    public static final Pattern SQL_PARAMS_PATTERN = Pattern.compile(SQL_PARAMS_REGEX);
	
	    public static final String AZURE_SQL_DATABASE_SPN = "https://database.windows.net/";
	    public static final String AZURE_SQL_DATABASE_TOKEN_SCOPE = "/.default";
	
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/TaskConstants.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.plugin.task.api;
	
	import org.apache.dolphinscheduler.common.constants.DateConstants;
	
	import java.time.Duration;
	import java.util.Set;
	import java.util.regex.Pattern;
	
	import com.google.common.collect.Sets;
	
	public class TaskConstants {
	
	    private TaskConstants() {
	        throw new IllegalStateException("Utility class");
	    }
	
	    public static final String YARN_APPLICATION_REGEX = "application_\\d+_\\d+";
	
	    public static final String FLINK_APPLICATION_REGEX = "JobID \\w+";
	
	    public static final String DATASOURCE_PASSWORD_REGEX =
	            "(?<=((?i)password((\" : \")|(\":\")|(\\\\\":\\\\\")|(=')))).*?(?=((\")|(\\\\\")|(')))";
	
	    /**
	     * exit code kill
	     */
	    public static final int EXIT_CODE_KILL = 137;
	    public static final String PID = "pid";
	
	    /**
	     * QUESTION ?
	     */
	    public static final String QUESTION = "?";
	
	    /**
	     * comma ,
	     */
	    public static final String COMMA = ",";
	
	    /**
	     * hyphen
	     */
	    public static final String HYPHEN = "-";
	
	    /**
	     * slash /
	     */
	    public static final String SLASH = "/";
	
	    /**
	     * COLON :
	     */
	    public static final String COLON = ":";
	
	    /**
	     * SPACE " "
	     */
	    public static final String SPACE = " ";
	
	    /**
	     * SINGLE_SLASH /
	     */
	    public static final String SINGLE_SLASH = "/";
	
	    /**
	     * DOUBLE_SLASH //
	     */
	    public static final String DOUBLE_SLASH = "//";
	
	    /**
	     * SINGLE_QUOTES "'"
	     */
	    public static final String SINGLE_QUOTES = "'";
	    /**
	     * DOUBLE_QUOTES "\""
	     */
	    public static final String DOUBLE_QUOTES = "\"";
	
	    /**
	     * SEMICOLON ;
	     */
	    public static final String SEMICOLON = ";";
	
	    /**
	     * EQUAL SIGN
	     */
	    public static final String EQUAL_SIGN = "=";
	
	    /**
	     * UNDERLINE
	     */
	    public static final String UNDERLINE = "_";
	
	    /**
	     * sleep time
	     */
	    public static final int SLEEP_TIME_MILLIS = 1000;
	
	    /**
	     * exit code failure
	     */
	    public static final int EXIT_CODE_FAILURE = -1;
	
	    /**
	     * exit code success
	     */
	    public static final int EXIT_CODE_SUCCESS = 0;
	    /**
	     * running code
	     */
	    public static final int RUNNING_CODE = 1;
	
	    public static final String SH = "sh";
	
	    /**
	     * log flush interval?output when reach the interval
	     */
	    public static final int DEFAULT_LOG_FLUSH_INTERVAL = 1000;
	
	    /**
	     * pstree, get pud and sub pid
	     */
	    public static final String PSTREE = "pstree";
	
	    public static final String RWXR_XR_X = "rwxr-xr-x";
	
	    /**
	     * date format of yyyyMMddHHmmss
	     */
	    public static final String PARAMETER_FORMAT_TIME = "yyyyMMddHHmmss";
	
	    /**
	     * new
	     * schedule time
	     */
	    public static final String PARAMETER_SHECDULE_TIME = "schedule.time";
	
	    /**
	     * system date(yyyyMMddHHmmss)
	     */
	    public static final String PARAMETER_DATETIME = DateConstants.PARAMETER_DATETIME;
	
	    /**
	     * system date(yyyymmdd) today
	     */
	    public static final String PARAMETER_CURRENT_DATE = DateConstants.PARAMETER_CURRENT_DATE;
	
	    /**
	     * system date(yyyymmdd) yesterday
	     */
	    public static final String PARAMETER_BUSINESS_DATE = DateConstants.PARAMETER_BUSINESS_DATE;
	
	    /**
	     * the absolute path of current executing task
	     */
	    public static final String PARAMETER_TASK_EXECUTE_PATH = "system.task.execute.path";
	
	    /**
	     * the instance id of current task
	     */
	    public static final String PARAMETER_TASK_INSTANCE_ID = "system.task.instance.id";
	
	    /**
	     * the definition code of current task
	     */
	    public static final String PARAMETER_TASK_DEFINITION_CODE = "system.task.definition.code";
	
	    /**
	     * the definition name of current task
	     */
	    public static final String PARAMETER_TASK_DEFINITION_NAME = "system.task.definition.name";
	
	    /**
	     * the instance id of the workflow to which current task belongs
	     */
	    public static final String PARAMETER_WORKFLOW_INSTANCE_ID = "system.workflow.instance.id";
	
	    /**
	     * the definition code of the workflow to which current task belongs
	     */
	    public static final String PARAMETER_WORKFLOW_DEFINITION_CODE = "system.workflow.definition.code";
	
	    /**
	     * the definition name of the workflow to which current task belongs
	     */
	    public static final String PARAMETER_WORKFLOW_DEFINITION_NAME = "system.workflow.definition.name";
	
	    /**
	     * the code of the project to which current task belongs
	     */
	    public static final String PARAMETER_PROJECT_CODE = "system.project.code";
	
	    /**
	     * the name of the project to which current task belongs
	     */
	    public static final String PARAMETER_PROJECT_NAME = "system.project.name";
	    /**
	     * month_begin
	     */
	    public static final String MONTH_BEGIN = "month_begin";
	    /**
	     * add_months
	     */
	    public static final String ADD_MONTHS = "add_months";
	    /**
	     * month_end
	     */
	    public static final String MONTH_END = "month_end";
	    /**
	     * week_begin
	     */
	    public static final String WEEK_BEGIN = "week_begin";
	    /**
	     * week_end
	     */
	    public static final String WEEK_END = "week_end";
	    /**
	     * this_day
	     */
	    public static final String THIS_DAY = "this_day";
	    /**
	     * last_day
	     */
	    public static final String LAST_DAY = "last_day";
	
	    /**
	     * month_first_day
	     */
	    public static final String MONTH_FIRST_DAY = "month_first_day";
	
	    /**
	     * month_last_day
	     */
	    public static final String MONTH_LAST_DAY = "month_last_day";
	
	    /**
	     * week_first_day
	     */
	    public static final String WEEK_FIRST_DAY = "week_first_day";
	
	    /**
	     * week_last_day
	     */
	    public static final String WEEK_LAST_DAY = "week_last_day";
	
	    /**
	     * year_week
	     */
	    public static final String YEAR_WEEK = "year_week";
	    /**
	     * timestamp
	     */
	    public static final String TIMESTAMP = "timestamp";
	    public static final char SUBTRACT_CHAR = '-';
	    public static final char ADD_CHAR = '+';
	    public static final char MULTIPLY_CHAR = '*';
	    public static final char DIVISION_CHAR = '/';
	    public static final char LEFT_BRACE_CHAR = '(';
	    public static final char RIGHT_BRACE_CHAR = ')';
	    public static final String ADD_STRING = "+";
	    public static final String MULTIPLY_STRING = "*";
	    public static final String DIVISION_STRING = "/";
	    public static final String LEFT_BRACE_STRING = "(";
	    public static final char P = 'P';
	    public static final char N = 'N';
	    public static final String SUBTRACT_STRING = "-";
	    public static final String LOCAL_PARAMS_LIST = "localParamsList";
	    public static final String TASK_TYPE = "taskType";
	    public static final String QUEUE = "queue";
	    /**
	     * default display rows
	     */
	    public static final int DEFAULT_DISPLAY_ROWS = 10;
	
	    /**
	     * jar
	     */
	    public static final String JAR = "jar";
	
	    /**
	     * hadoop
	     */
	    public static final String HADOOP = "hadoop";
	
	    /**
	     * -D <property>=<value>
	     */
	    public static final String D = "-D";
	
	    /**
	     * java.security.krb5.conf
	     */
	    public static final String JAVA_SECURITY_KRB5_CONF = "java.security.krb5.conf";
	
	    /**
	     * java.security.krb5.conf.path
	     */
	    public static final String JAVA_SECURITY_KRB5_CONF_PATH = "java.security.krb5.conf.path";
	
	    /**
	     * hadoop.security.authentication
	     */
	    public static final String HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE =
	            "hadoop.security.authentication.startup.state";
	
	    public static final String TASK_TYPE_DATA_QUALITY = "DATA_QUALITY";
	
	    public static final Set<String> TASK_TYPE_SET_K8S = Sets.newHashSet("K8S", "KUBEFLOW");
	
	    /**
	     * azure config
	     */
	    public static final String AZURE_CLIENT_ID = "resource.azure.client.id";
	    public static final String AZURE_CLIENT_SECRET = "resource.azure.client.secret";
	    public static final String AZURE_ACCESS_SUB_ID = "resource.azure.subId";
	    public static final String AZURE_SECRET_TENANT_ID = "resource.azure.tenant.id";
	    public static final String QUERY_INTERVAL = "resource.query.interval";
	
	    /**
	     * use for k8s task
	     */
	    public static final String API_VERSION = "batch/v1";
	    public static final String RESTART_POLICY = "Never";
	    public static final String MEMORY = "memory";
	    public static final String CPU = "cpu";
	    public static final String LAYER_LABEL = "k8s.cn/layer";
	    public static final String LAYER_LABEL_VALUE = "batch";
	    public static final String NAME_LABEL = "k8s.cn/name";
	    public static final String TASK_INSTANCE_ID = "taskInstanceId";
	    public static final String MI = "Mi";
	    public static final int JOB_TTL_SECONDS = 300;
	    public static final int LOG_LINES = 500;
	    public static final String NAMESPACE_NAME = "name";
	    public static final String CLUSTER = "cluster";
	
	    /**
	     * spark / flink on k8s label name
	     */
	    public static final String UNIQUE_LABEL_NAME = "dolphinscheduler-label";
	
	    /**
	     * conda config used by jupyter task plugin
	     */
	    public static final String CONDA_PATH = "conda.path";
	
	    // Loop task constants
	    public static final Duration DEFAULT_LOOP_STATUS_INTERVAL = Duration.ofSeconds(5L);
	
	    /**
	     * sql params regex
	     */
	    public static final String GROUP_NAME1 = "paramName1";
	    public static final String GROUP_NAME2 = "paramName2";
	    public static final String SQL_PARAMS_REGEX =
	            String.format("['\"]\\$\\{(?<%s>.*?)}['\"]|\\$\\{(?<%s>.*?)}", GROUP_NAME1, GROUP_NAME2);
	    public static final Pattern SQL_PARAMS_PATTERN = Pattern.compile(SQL_PARAMS_REGEX);
	
	    public static final String LOGIN_USER_KEY_TAB_USERNAME = "login.user.keytab.username";
	
	    public static final String LOGIN_USER_KEY_TAB_PATH = "login.user.keytab.path";
	
	    /**
	     * fetch applicationId way
	     */
	    public static final String APPID_COLLECT = "appId.collect";
	    public static final String DEFAULT_COLLECT_WAY = "log";
	
	    public static final String WORKFLOW_INSTANCE_ID_MDC_KEY = "workflowInstanceId";
	    public static final String TASK_INSTANCE_ID_MDC_KEY = "taskInstanceId";
	
	    public static final String STAR = "*";
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/constants/DataSourceConstants.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.common.constants;
	
	public class DataSourceConstants {
	
	    public static final String DATASOURCE = "datasource";
	
	    /**
	     * driver
	     */
	    public static final String ORG_POSTGRESQL_DRIVER = "org.postgresql.Driver";
	    public static final String COM_MYSQL_CJ_JDBC_DRIVER = "com.mysql.cj.jdbc.Driver";
	    public static final String COM_MYSQL_JDBC_DRIVER = "com.mysql.jdbc.Driver";
	    public static final String ORG_APACHE_HIVE_JDBC_HIVE_DRIVER = "org.apache.hive.jdbc.HiveDriver";
	    public static final String COM_CLICKHOUSE_JDBC_DRIVER = "com.clickhouse.jdbc.ClickHouseDriver";
	    public static final String COM_DATABEND_JDBC_DRIVER = "com.databend.jdbc.DatabendDriver";
	    public static final String COM_ORACLE_JDBC_DRIVER = "oracle.jdbc.OracleDriver";
	    public static final String COM_SQLSERVER_JDBC_DRIVER = "com.microsoft.sqlserver.jdbc.SQLServerDriver";
	    public static final String COM_DB2_JDBC_DRIVER = "com.ibm.db2.jcc.DB2Driver";
	    public static final String COM_PRESTO_JDBC_DRIVER = "com.facebook.presto.jdbc.PrestoDriver";
	    public static final String COM_REDSHIFT_JDBC_DRIVER = "com.amazon.redshift.jdbc42.Driver";
	    public static final String COM_ATHENA_JDBC_DRIVER = "com.simba.athena.jdbc.Driver";
	    public static final String COM_TRINO_JDBC_DRIVER = "io.trino.jdbc.TrinoDriver";
	    public static final String COM_DAMENG_JDBC_DRIVER = "dm.jdbc.driver.DmDriver";
	    public static final String ORG_APACHE_KYUUBI_JDBC_DRIVER = "org.apache.kyuubi.jdbc.KyuubiHiveDriver";
	    public static final String COM_OCEANBASE_JDBC_DRIVER = "com.oceanbase.jdbc.Driver";
	    public static final String NET_SNOWFLAKE_JDBC_DRIVER = "net.snowflake.client.jdbc.SnowflakeDriver";
	    public static final String COM_VERTICA_JDBC_DRIVER = "com.vertica.jdbc.Driver";
	    public static final String COM_HANA_DB_JDBC_DRIVER = "com.sap.db.jdbc.Driver";
	
	    /**
	     * validation Query
	     */
	    public static final String POSTGRESQL_VALIDATION_QUERY = "select version()";
	    public static final String MYSQL_VALIDATION_QUERY = "select 1";
	    public static final String HIVE_VALIDATION_QUERY = "select 1";
	    public static final String CLICKHOUSE_VALIDATION_QUERY = "select 1";
	    public static final String DATABEND_VALIDATION_QUERY = "select 1";
	    public static final String ORACLE_VALIDATION_QUERY = "select 1 from dual";
	    public static final String SQLSERVER_VALIDATION_QUERY = "select 1";
	    public static final String DB2_VALIDATION_QUERY = "select 1 from sysibm.sysdummy1";
	    public static final String PRESTO_VALIDATION_QUERY = "select 1";
	    public static final String REDHIFT_VALIDATION_QUERY = "select 1";
	    public static final String ATHENA_VALIDATION_QUERY = "select 1";
	    public static final String TRINO_VALIDATION_QUERY = "select 1";
	    public static final String DAMENG_VALIDATION_QUERY = "select 1";
	    public static final String SNOWFLAKE_VALIDATION_QUERY = "select 1";
	
	    public static final String KYUUBI_VALIDATION_QUERY = "select 1";
	    public static final String VERTICA_VALIDATION_QUERY = "select 1";
	
	    public static final String HANA_VALIDATION_QUERY = "select 1 from DUMMY";
	
	    /**
	     * jdbc url
	     */
	    public static final String JDBC_MYSQL = "jdbc:mysql://";
	    public static final String JDBC_MYSQL_LOADBALANCE = "jdbc:mysql:loadbalance://";
	    public static final String JDBC_POSTGRESQL = "jdbc:postgresql://";
	    public static final String JDBC_HIVE_2 = "jdbc:hive2://";
	    public static final String JDBC_KYUUBI = "jdbc:kyuubi://";
	    public static final String JDBC_CLICKHOUSE = "jdbc:clickhouse://";
	    public static final String JDBC_DATABEND = "jdbc:databend://";
	    public static final String JDBC_ORACLE_SID = "jdbc:oracle:thin:@";
	    public static final String JDBC_ORACLE_SERVICE_NAME = "jdbc:oracle:thin:@//";
	    public static final String JDBC_SQLSERVER = "jdbc:sqlserver://";
	    public static final String JDBC_DB2 = "jdbc:db2://";
	    public static final String JDBC_PRESTO = "jdbc:presto://";
	    public static final String JDBC_REDSHIFT = "jdbc:redshift://";
	    public static final String JDBC_REDSHIFT_IAM = "jdbc:redshift:iam://";
	    public static final String JDBC_ATHENA = "jdbc:awsathena://";
	    public static final String JDBC_TRINO = "jdbc:trino://";
	    public static final String JDBC_DAMENG = "jdbc:dm://";
	    public static final String JDBC_OCEANBASE = "jdbc:oceanbase://";
	    public static final String JDBC_SNOWFLAKE = "jdbc:snowflake://";
	    public static final String JDBC_VERTICA = "jdbc:vertica://";
	    public static final String JDBC_HANA = "jdbc:sap://";
	
	    /**
	     * database type
	     */
	    public static final String MYSQL = "MYSQL";
	    public static final String HIVE = "HIVE";
	
	    /**
	     * dataSource sensitive param
	     */
	    public static final String DATASOURCE_PASSWORD_REGEX =
	            "(?<=((?i)password((\" : \")|(\":\")|(\\\\\":\\\\\")|(=')))).*?(?=((\")|(\\\\\")|(')))";
	
	    /**
	     * datasource encryption salt
	     */
	    public static final String DATASOURCE_ENCRYPTION_SALT_DEFAULT = "!@#$%^&*";
	    public static final String DATASOURCE_ENCRYPTION_ENABLE = "datasource.encryption.enable";
	    public static final String DATASOURCE_ENCRYPTION_SALT = "datasource.encryption.salt";
	
	    /**
	     * datasource config
	     */
	    public static final String SPRING_DATASOURCE_MIN_IDLE = "spring.datasource.minIdle";
	
	    public static final String SPRING_DATASOURCE_MAX_ACTIVE = "spring.datasource.maxActive";
	
	    public static final String SPRING_DATASOURCE_TEST_ON_BORROW = "spring.datasource.testOnBorrow";
	
	    /**
	     * azure static websites
	     */
	    public static final String AZURE_SQL_DATABASE_SPN = "https://database.windows.net/";
	    public static final String AZURE_SQL_DATABASE_TOKEN_SCOPE = "/.default";
	
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.dao.entity;
	
	import org.apache.dolphinscheduler.common.enums.Flag;
	import org.apache.dolphinscheduler.common.enums.Priority;
	import org.apache.dolphinscheduler.common.enums.TaskExecuteType;
	import org.apache.dolphinscheduler.plugin.task.api.enums.TaskExecutionStatus;
	
	import java.io.Serializable;
	import java.util.Date;
	
	import lombok.Data;
	
	import com.baomidou.mybatisplus.annotation.FieldStrategy;
	import com.baomidou.mybatisplus.annotation.IdType;
	import com.baomidou.mybatisplus.annotation.TableField;
	import com.baomidou.mybatisplus.annotation.TableId;
	import com.baomidou.mybatisplus.annotation.TableName;
	
	@Data
	@TableName("t_ds_task_instance")
	public class TaskInstance implements Serializable {
	
	    @TableId(value = "id", type = IdType.AUTO)
	    private Integer id;
	
	    private String name;
	
	    private String taskType;
	
	    private int workflowInstanceId;
	
	    private String workflowInstanceName;
	
	    private Long projectCode;
	
	    private long taskCode;
	
	    private int taskDefinitionVersion;
	
	    @TableField(exist = false)
	    private String processDefinitionName;
	
	    @TableField(exist = false)
	    private int taskGroupPriority;
	
	    private TaskExecutionStatus state;
	
	    private Date firstSubmitTime;
	
	    private Date submitTime;
	
	    private Date startTime;
	
	    private Date endTime;
	
	    private String host;
	
	    private String executePath;
	
	    private String logPath;
	
	    private int retryTimes;
	
	    private Flag alertFlag;
	
	    @TableField(exist = false)
	    private WorkflowInstance workflowInstance;
	
	    @TableField(exist = false)
	    private WorkflowDefinition workflowDefinition;
	
	    @TableField(exist = false)
	    private TaskDefinition taskDefine;
	
	    private int pid;
	
	    private String appLink;
	
	    private Flag flag;
	
	    private Flag isCache;
	
	    @TableField(updateStrategy = FieldStrategy.IGNORED)
	    private String cacheKey;
	
	    @TableField(exist = false)
	    private String duration;
	
	    private int maxRetryTimes;
	
	    private int retryInterval;
	
	    private Priority taskInstancePriority;
	
	    @TableField(exist = false)
	    private Priority workflowInstancePriority;
	
	    private String workerGroup;
	
	    private Long environmentCode;
	
	    private String environmentConfig;
	
	    private int executorId;
	
	    private String varPool;
	
	    private String executorName;
	
	    private int delayTime;
	
	    private String taskParams;
	
	    private int dryRun;
	
	    private int taskGroupId;
	
	    private Integer cpuQuota;
	
	    private Integer memoryMax;
	
	    private TaskExecuteType taskExecuteType;
	
	    private int testFlag;
	
	    public void init(String host, Date startTime, String executePath) {
	        this.host = host;
	        this.startTime = startTime;
	        this.executePath = executePath;
	    }
	
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-extract/dolphinscheduler-extract-master/src/main/java/org/apache/dolphinscheduler/extract/master/dto/TaskInstanceExecuteDto.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.extract.master.dto;
	
	import org.apache.dolphinscheduler.common.enums.Flag;
	import org.apache.dolphinscheduler.common.enums.Priority;
	import org.apache.dolphinscheduler.common.enums.TaskExecuteType;
	import org.apache.dolphinscheduler.plugin.task.api.enums.TaskExecutionStatus;
	
	import java.util.Date;
	import java.util.Map;
	
	import lombok.Data;
	
	@Data
	public class TaskInstanceExecuteDto {
	
	    private int id;
	
	    private String name;
	
	    private String taskType;
	
	    private int processInstanceId;
	
	    private long taskCode;
	
	    private int taskDefinitionVersion;
	
	    private String processInstanceName;
	
	    private int taskGroupPriority;
	
	    private TaskExecutionStatus state;
	
	    private Date firstSubmitTime;
	
	    private Date submitTime;
	
	    private Date startTime;
	
	    private Date endTime;
	
	    private String host;
	
	    private String executePath;
	
	    private String logPath;
	
	    private int retryTimes;
	
	    private Flag alertFlag;
	
	    private int pid;
	
	    private String appLink;
	
	    private Flag flag;
	
	    private String duration;
	
	    private int maxRetryTimes;
	
	    private int retryInterval;
	
	    private Priority taskInstancePriority;
	
	    private Priority processInstancePriority;
	
	    private String workerGroup;
	
	    private Long environmentCode;
	
	    private String environmentConfig;
	
	    private int executorId;
	
	    private String varPool;
	
	    private String executorName;
	
	    private Map<String, String> resources;
	
	    private int delayTime;
	
	    private String taskParams;
	
	    private int dryRun;
	
	    private int taskGroupId;
	
	    private Integer cpuQuota;
	
	    private Integer memoryMax;
	
	    private TaskExecuteType taskExecuteType;
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.controller;
	
	import static org.apache.dolphinscheduler.api.enums.Status.CREATE_ACCESS_TOKEN_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.DELETE_ACCESS_TOKEN_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.GENERATE_TOKEN_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ACCESSTOKEN_BY_USER_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ACCESSTOKEN_LIST_PAGING_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_ACCESS_TOKEN_ERROR;
	
	import org.apache.dolphinscheduler.api.audit.OperatorLog;
	import org.apache.dolphinscheduler.api.audit.enums.AuditType;
	import org.apache.dolphinscheduler.api.exceptions.ApiException;
	import org.apache.dolphinscheduler.api.service.AccessTokenService;
	import org.apache.dolphinscheduler.api.utils.PageInfo;
	import org.apache.dolphinscheduler.api.utils.Result;
	import org.apache.dolphinscheduler.common.constants.Constants;
	import org.apache.dolphinscheduler.dao.entity.AccessToken;
	import org.apache.dolphinscheduler.dao.entity.User;
	import org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils;
	
	import java.util.List;
	
	import org.springframework.beans.factory.annotation.Autowired;
	import org.springframework.http.HttpStatus;
	import org.springframework.web.bind.annotation.DeleteMapping;
	import org.springframework.web.bind.annotation.GetMapping;
	import org.springframework.web.bind.annotation.PathVariable;
	import org.springframework.web.bind.annotation.PostMapping;
	import org.springframework.web.bind.annotation.PutMapping;
	import org.springframework.web.bind.annotation.RequestAttribute;
	import org.springframework.web.bind.annotation.RequestMapping;
	import org.springframework.web.bind.annotation.RequestParam;
	import org.springframework.web.bind.annotation.ResponseStatus;
	import org.springframework.web.bind.annotation.RestController;
	
	import io.swagger.v3.oas.annotations.Operation;
	import io.swagger.v3.oas.annotations.Parameter;
	import io.swagger.v3.oas.annotations.Parameters;
	import io.swagger.v3.oas.annotations.media.Schema;
	import io.swagger.v3.oas.annotations.tags.Tag;
	
	/**
	 * access token controller
	 */
	@Tag(name = "ACCESS_TOKEN_TAG")
	@RestController
	@RequestMapping("/access-tokens")
	public class AccessTokenController extends BaseController {
	
	    @Autowired
	    private AccessTokenService accessTokenService;
	
	    /**
	     * create token
	     *
	     * @param loginUser login user
	     * @param userId token for user id
	     * @param expireTime expire time for the token
	     * @param token token string (if it is absent, it will be automatically generated)
	     * @return create result state code
	     */
	    @Operation(summary = "createToken", description = "CREATE_TOKEN_NOTES")
	    @Parameters({
	            @Parameter(name = "userId", description = "USER_ID", schema = @Schema(implementation = int.class), required = true),
	            @Parameter(name = "expireTime", description = "EXPIRE_TIME", schema = @Schema(implementation = String.class), required = true, example = "2021-12-31 00:00:00"),
	            @Parameter(name = "token", description = "TOKEN", required = false, schema = @Schema(implementation = String.class), example = "xxxx")
	    })
	    @PostMapping()
	    @ResponseStatus(HttpStatus.CREATED)
	    @ApiException(CREATE_ACCESS_TOKEN_ERROR)
	    @OperatorLog(auditType = AuditType.TOKEN_CREATE)
	    public Result<AccessToken> createToken(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                           @RequestParam(value = "userId") int userId,
	                                           @RequestParam(value = "expireTime") String expireTime,
	                                           @RequestParam(value = "token", required = false) String token) {
	
	        AccessToken accessToken = accessTokenService.createToken(loginUser, userId, expireTime, token);
	        return Result.success(accessToken);
	    }
	
	    /**
	     * generate token string
	     *
	     * @param loginUser login user
	     * @param userId token for user
	     * @param expireTime expire time
	     * @return token string
	     */
	    @Parameter(hidden = true)
	    @PostMapping(value = "/generate")
	    @ResponseStatus(HttpStatus.CREATED)
	    @ApiException(GENERATE_TOKEN_ERROR)
	    public Result<String> generateToken(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                        @RequestParam(value = "userId") int userId,
	                                        @RequestParam(value = "expireTime") String expireTime) {
	        String token = accessTokenService.generateToken(loginUser, userId, expireTime);
	        return Result.success(token);
	    }
	
	    /**
	     * query access token list paging
	     *
	     * @param loginUser login user
	     * @param pageNo page number
	     * @param searchVal search value
	     * @param pageSize page size
	     * @return token list of page number and page size
	     */
	    @Operation(summary = "queryAccessTokenList", description = "QUERY_ACCESS_TOKEN_LIST_NOTES")
	    @Parameters({
	            @Parameter(name = "searchVal", description = "SEARCH_VAL", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "pageNo", description = "PAGE_NO", required = true, schema = @Schema(implementation = int.class), example = "1"),
	            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class), example = "20")
	    })
	    @GetMapping()
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_ACCESSTOKEN_LIST_PAGING_ERROR)
	    public Result<PageInfo<AccessToken>> queryAccessTokenList(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                              @RequestParam("pageNo") Integer pageNo,
	                                                              @RequestParam(value = "searchVal", required = false) String searchVal,
	                                                              @RequestParam("pageSize") Integer pageSize) {
	
	        checkPageParams(pageNo, pageSize);
	        searchVal = ParameterUtils.handleEscapes(searchVal);
	        PageInfo<AccessToken> accessTokenPageInfo =
	                accessTokenService.queryAccessTokenList(loginUser, searchVal, pageNo, pageSize);
	        return Result.success(accessTokenPageInfo);
	    }
	
	    /**
	     * query access token for specified user
	     *
	     * @param loginUser login user
	     * @param userId user id
	     * @return token list for specified user
	     */
	    @Operation(summary = "queryAccessTokenByUser", description = "QUERY_ACCESS_TOKEN_BY_USER_NOTES")
	    @Parameters({
	            @Parameter(name = "userId", description = "USER_ID", schema = @Schema(implementation = int.class))
	    })
	    @GetMapping(value = "/user/{userId}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_ACCESSTOKEN_BY_USER_ERROR)
	    public Result<List<AccessToken>> queryAccessTokenByUser(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                            @PathVariable("userId") Integer userId) {
	        List<AccessToken> accessTokens = accessTokenService.queryAccessTokenByUser(loginUser, userId);
	        return Result.success(accessTokens);
	    }
	
	    /**
	     * delete access token by id
	     *
	     * @param loginUser login user
	     * @param id token id
	     * @return delete result code
	     */
	    @Parameter(hidden = true)
	    @Operation(summary = "deleteToken", description = "DELETE_TOKEN_NOTES")
	    @DeleteMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(DELETE_ACCESS_TOKEN_ERROR)
	    @OperatorLog(auditType = AuditType.TOKEN_DELETE)
	    public Result<Boolean> delAccessTokenById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                              @PathVariable(value = "id") int id) {
	        accessTokenService.deleteAccessTokenById(loginUser, id);
	        return Result.success(false);
	    }
	
	    /**
	     * update token
	     *
	     * @param loginUser login user
	     * @param id token id
	     * @param userId token for user
	     * @param expireTime token expire time
	     * @param token token string (if it is absent, it will be automatically generated)
	     * @return updated access token entity
	     */
	    @Operation(summary = "updateToken", description = "UPDATE_TOKEN_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "TOKEN_ID", required = true, schema = @Schema(implementation = int.class)),
	            @Parameter(name = "userId", description = "USER_ID", required = true, schema = @Schema(implementation = int.class)),
	            @Parameter(name = "expireTime", description = "EXPIRE_TIME", required = true, schema = @Schema(implementation = String.class), example = "2021-12-31 00:00:00"),
	            @Parameter(name = "token", description = "TOKEN", required = false, schema = @Schema(implementation = String.class), example = "xxxx")
	    })
	    @PutMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(UPDATE_ACCESS_TOKEN_ERROR)
	    @OperatorLog(auditType = AuditType.TOKEN_UPDATE)
	    public Result<AccessToken> updateToken(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                           @PathVariable(value = "id") int id,
	                                           @RequestParam(value = "userId") int userId,
	                                           @RequestParam(value = "expireTime") String expireTime,
	                                           @RequestParam(value = "token", required = false) String token) {
	
	        AccessToken accessToken = accessTokenService.updateToken(loginUser, id, userId, expireTime, token);
	        return Result.success(accessToken);
	    }
	
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/AccessTokenService.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.service;
	
	import org.apache.dolphinscheduler.api.utils.PageInfo;
	import org.apache.dolphinscheduler.dao.entity.AccessToken;
	import org.apache.dolphinscheduler.dao.entity.User;
	
	import java.util.List;
	
	/**
	 * access token service
	 */
	public interface AccessTokenService {
	
	    /**
	     * query access token list
	     *
	     * @param loginUser login user
	     * @param searchVal search value
	     * @param pageNo page number
	     * @param pageSize page size
	     * @return token list for page number and page size
	     */
	    PageInfo<AccessToken> queryAccessTokenList(User loginUser, String searchVal, Integer pageNo, Integer pageSize);
	
	    /**
	     * query access token for specified user
	     *
	     * @param loginUser login user
	     * @param userId user id
	     * @return token list for specified user
	     */
	    List<AccessToken> queryAccessTokenByUser(User loginUser, Integer userId);
	
	    /**
	     * create token
	     *
	     * @param userId token for user
	     * @param expireTime token expire time
	     * @param token token string (if it is absent, it will be automatically generated)
	     * @return create result code
	     */
	    AccessToken createToken(User loginUser, int userId, String expireTime, String token);
	
	    /**
	     * generate token
	     *
	     * @param userId token for user
	     * @param expireTime token expire time
	     * @return token string
	     */
	    String generateToken(User loginUser, int userId, String expireTime);
	
	    /**
	     * delete access token
	     *
	     * @param loginUser login user
	     * @param id token id
	     * @return delete result code
	     */
	    void deleteAccessTokenById(User loginUser, int id);
	
	    /**
	     * update token by id
	     *
	     * @param id token id
	     * @param userId token for user
	     * @param expireTime token expire time
	     * @param token token string (if it is absent, it will be automatically generated)
	     * @return updated access token entity
	     */
	    AccessToken updateToken(User loginUser, int id, int userId, String expireTime, String token);
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/EnvironmentDto.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.dto;
	
	import java.util.Date;
	import java.util.List;
	
	import lombok.Data;
	
	@Data
	public class EnvironmentDto {
	
	    private Integer id;
	
	    /**
	     * environment code
	     */
	    private Long code;
	
	    /**
	     * environment name
	     */
	    private String name;
	
	    /**
	     * config content
	     */
	    private String config;
	
	    private String description;
	
	    private List<String> workerGroups;
	
	    /**
	     * operator user id
	     */
	    private Integer operator;
	
	    private Date createTime;
	
	    private Date updateTime;
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/AccessToken.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.dao.entity;
	
	import java.util.Date;
	import java.util.Objects;
	
	import lombok.Data;
	
	import com.baomidou.mybatisplus.annotation.IdType;
	import com.baomidou.mybatisplus.annotation.TableField;
	import com.baomidou.mybatisplus.annotation.TableId;
	import com.baomidou.mybatisplus.annotation.TableName;
	
	@Data
	@TableName("t_ds_access_token")
	public class AccessToken {
	
	    /**
	     * primary key
	     */
	    @TableId(value = "id", type = IdType.AUTO)
	    private Integer id;
	    /**
	     * user_id
	     */
	    @TableField(value = "user_id")
	    private int userId;
	    /**
	     * token
	     */
	    @TableField(value = "token")
	    private String token;
	    /**
	     * expire_time
	     */
	    @TableField(value = "expire_time")
	    private Date expireTime;
	    /**
	     * create_time
	     */
	    @TableField(value = "create_time")
	    private Date createTime;
	    /**
	     * update_time
	     */
	    @TableField(value = "update_time")
	    private Date updateTime;
	    @TableField(exist = false)
	    private String userName;
	
	    @Override
	    public boolean equals(Object o) {
	        if (this == o) {
	            return true;
	        }
	        if (o == null || getClass() != o.getClass()) {
	            return false;
	        }
	        AccessToken that = (AccessToken) o;
	
	        if (!Objects.equals(id, that.id)) {
	            return false;
	        }
	        if (userId != that.userId) {
	            return false;
	        }
	        if (userName != null && !userName.equals(that.userName)) {
	            return false;
	        }
	        if (token != null && !token.equals(that.token)) {
	            return false;
	        }
	        if (expireTime != null && !expireTime.equals(that.expireTime)) {
	            return false;
	        }
	        if (createTime != null && !createTime.equals(that.createTime)) {
	            return false;
	        }
	        if (updateTime != null && !updateTime.equals(that.updateTime)) {
	            return false;
	        }
	        return true;
	    }
	
	    @Override
	    public int hashCode() {
	        int result = id;
	        result = 31 * result + userId;
	        result = 31 * result + (userName != null ? userName.hashCode() : 0);
	        result = 31 * result + (token != null ? token.hashCode() : 0);
	        result = 31 * result + (expireTime != null ? expireTime.hashCode() : 0);
	        result = 31 * result + (createTime != null ? createTime.hashCode() : 0);
	        result = 31 * result + (updateTime != null ? updateTime.hashCode() : 0);
	        return result;
	    }
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AuditLogController.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.controller;
	
	import static org.apache.dolphinscheduler.api.enums.Status.QUERY_AUDIT_LOG_LIST_PAGING;
	
	import org.apache.dolphinscheduler.api.dto.AuditDto;
	import org.apache.dolphinscheduler.api.dto.auditLog.AuditModelTypeDto;
	import org.apache.dolphinscheduler.api.dto.auditLog.AuditOperationTypeDto;
	import org.apache.dolphinscheduler.api.exceptions.ApiException;
	import org.apache.dolphinscheduler.api.service.AuditService;
	import org.apache.dolphinscheduler.api.utils.PageInfo;
	import org.apache.dolphinscheduler.api.utils.Result;
	import org.apache.dolphinscheduler.common.constants.Constants;
	import org.apache.dolphinscheduler.dao.entity.User;
	
	import java.util.List;
	
	import org.springframework.beans.factory.annotation.Autowired;
	import org.springframework.http.HttpStatus;
	import org.springframework.web.bind.annotation.GetMapping;
	import org.springframework.web.bind.annotation.RequestAttribute;
	import org.springframework.web.bind.annotation.RequestMapping;
	import org.springframework.web.bind.annotation.RequestParam;
	import org.springframework.web.bind.annotation.ResponseStatus;
	import org.springframework.web.bind.annotation.RestController;
	
	import io.swagger.v3.oas.annotations.Operation;
	import io.swagger.v3.oas.annotations.Parameter;
	import io.swagger.v3.oas.annotations.Parameters;
	import io.swagger.v3.oas.annotations.media.Schema;
	import io.swagger.v3.oas.annotations.tags.Tag;
	
	@Tag(name = "AUDIT_LOG_TAG")
	@RestController
	@RequestMapping("projects/audit")
	public class AuditLogController extends BaseController {
	
	    @Autowired
	    AuditService auditService;
	
	    /**
	     * query audit log list paging
	     *
	     * @param loginUser         login user
	     * @param pageNo            page number
	     * @param pageSize          page size
	     * @param modelTypes        model types
	     * @param operationTypes    operation types
	     * @param userName          user name
	     * @param modelName         model name
	     * @param startDate         start time
	     * @param endDate           end time
	     * @return      audit log content
	     */
	    @Operation(summary = "queryAuditLogListPaging", description = "QUERY_AUDIT_LOG")
	    @Parameters({
	            @Parameter(name = "startDate", description = "START_DATE", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "endDate", description = "END_DATE", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "objectTypes", description = "MODEL_TYPES", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "operationTypes", description = "OPERATION_TYPES", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "userName", description = "USER_NAME", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "objectName", description = "MODEL_NAME", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "pageNo", description = "PAGE_NO", required = true, schema = @Schema(implementation = int.class, example = "1")),
	            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "20"))
	    })
	    @GetMapping(value = "/audit-log-list")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_AUDIT_LOG_LIST_PAGING)
	    public Result<PageInfo<AuditDto>> queryAuditLogListPaging(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                              @RequestParam("pageNo") Integer pageNo,
	                                                              @RequestParam("pageSize") Integer pageSize,
	                                                              @RequestParam(value = "modelTypes", required = false) String modelTypes,
	                                                              @RequestParam(value = "operationTypes", required = false) String operationTypes,
	                                                              @RequestParam(value = "startDate", required = false) String startDate,
	                                                              @RequestParam(value = "endDate", required = false) String endDate,
	                                                              @RequestParam(value = "userName", required = false) String userName,
	                                                              @RequestParam(value = "modelName", required = false) String modelName) {
	        checkPageParams(pageNo, pageSize);
	        PageInfo<AuditDto> auditDtoPageInfo = auditService.queryLogListPaging(
	                modelTypes,
	                operationTypes,
	                startDate,
	                endDate,
	                userName,
	                modelName,
	                pageNo,
	                pageSize);
	        return Result.success(auditDtoPageInfo);
	    }
	
	    /**
	     * query audit log operation type list
	     *
	     * @return object type list
	     */
	    @Operation(summary = "queryAuditOperationTypeList", description = "QUERY_AUDIT_OPERATION_TYPE_LIST")
	    @GetMapping(value = "/audit-log-operation-type")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_AUDIT_LOG_LIST_PAGING)
	    public Result<List<AuditOperationTypeDto>> queryAuditOperationTypeList() {
	        return Result.success(AuditOperationTypeDto.getOperationTypeDtoList());
	    }
	
	    /**
	     * query audit log model type list
	     *
	     * @return model type list
	     */
	    @Operation(summary = "queryAuditModelTypeList", description = "QUERY_AUDIT_MODEL_TYPE_LIST")
	    @GetMapping(value = "/audit-log-model-type")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_AUDIT_LOG_LIST_PAGING)
	    public Result<List<AuditModelTypeDto>> queryAuditModelTypeList() {
	        return Result.success(AuditModelTypeDto.getModelTypeDtoList());
	    }
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkflowInstanceController.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.controller;
	
	import static org.apache.dolphinscheduler.api.enums.Status.QUERY_WORKFLOW_INSTANCE_LIST_PAGING_ERROR;
	
	import org.apache.dolphinscheduler.api.audit.OperatorLog;
	import org.apache.dolphinscheduler.api.audit.enums.AuditType;
	import org.apache.dolphinscheduler.api.dto.DynamicSubWorkflowDto;
	import org.apache.dolphinscheduler.api.enums.Status;
	import org.apache.dolphinscheduler.api.exceptions.ApiException;
	import org.apache.dolphinscheduler.api.service.WorkflowInstanceService;
	import org.apache.dolphinscheduler.api.utils.Result;
	import org.apache.dolphinscheduler.common.constants.Constants;
	import org.apache.dolphinscheduler.common.enums.WorkflowExecutionStatus;
	import org.apache.dolphinscheduler.dao.entity.User;
	import org.apache.dolphinscheduler.dao.entity.WorkflowInstance;
	import org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils;
	
	import org.apache.commons.lang3.StringUtils;
	
	import java.io.IOException;
	import java.text.MessageFormat;
	import java.util.ArrayList;
	import java.util.HashMap;
	import java.util.List;
	import java.util.Map;
	
	import lombok.extern.slf4j.Slf4j;
	
	import org.springframework.beans.factory.annotation.Autowired;
	import org.springframework.http.HttpStatus;
	import org.springframework.web.bind.annotation.DeleteMapping;
	import org.springframework.web.bind.annotation.GetMapping;
	import org.springframework.web.bind.annotation.PathVariable;
	import org.springframework.web.bind.annotation.PostMapping;
	import org.springframework.web.bind.annotation.PutMapping;
	import org.springframework.web.bind.annotation.RequestAttribute;
	import org.springframework.web.bind.annotation.RequestMapping;
	import org.springframework.web.bind.annotation.RequestParam;
	import org.springframework.web.bind.annotation.ResponseStatus;
	import org.springframework.web.bind.annotation.RestController;
	
	import io.swagger.v3.oas.annotations.Operation;
	import io.swagger.v3.oas.annotations.Parameter;
	import io.swagger.v3.oas.annotations.Parameters;
	import io.swagger.v3.oas.annotations.media.Schema;
	import io.swagger.v3.oas.annotations.tags.Tag;
	
	/**
	 * workflow instance controller
	 */
	@Tag(name = "WORKFLOW_INSTANCE_TAG")
	@RestController
	@RequestMapping("/projects/{projectCode}/workflow-instances")
	@Slf4j
	public class WorkflowInstanceController extends BaseController {
	
	    @Autowired
	    private WorkflowInstanceService workflowInstanceService;
	
	    /**
	     * query workflow instance list paging
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param pageNo page number
	     * @param pageSize page size
	     * @param workflowDefinitionCode workflow definition code
	     * @param searchVal search value
	     * @param stateType state type
	     * @param host host
	     * @param startTime start time
	     * @param endTime end time
	     * @param otherParamsJson otherParamsJson handle other params
	     * @return workflow instance list
	     */
	    @Operation(summary = "queryWorkflowInstanceListPaging", description = "QUERY_WORKFLOW_INSTANCE_LIST_NOTES")
	    @Parameters({
	            @Parameter(name = "workflowDefinitionCode", description = "WORKFLOW_DEFINITION_CODE", schema = @Schema(implementation = long.class, example = "100")),
	            @Parameter(name = "searchVal", description = "SEARCH_VAL", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "executorName", description = "EXECUTOR_NAME", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "stateType", description = "EXECUTION_STATUS", schema = @Schema(implementation = WorkflowExecutionStatus.class)),
	            @Parameter(name = "host", description = "HOST", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "startDate", description = "START_DATE", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "endDate", description = "END_DATE", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "pageNo", description = "PAGE_NO", required = true, schema = @Schema(implementation = int.class, example = "1")),
	            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "10"))
	    })
	    @GetMapping()
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_LIST_PAGING_ERROR)
	    public Result queryWorkflowInstanceList(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                            @RequestParam(value = "workflowDefinitionCode", required = false, defaultValue = "0") long workflowDefinitionCode,
	                                            @RequestParam(value = "searchVal", required = false) String searchVal,
	                                            @RequestParam(value = "executorName", required = false) String executorName,
	                                            @RequestParam(value = "stateType", required = false) WorkflowExecutionStatus stateType,
	                                            @RequestParam(value = "host", required = false) String host,
	                                            @RequestParam(value = "startDate", required = false) String startTime,
	                                            @RequestParam(value = "endDate", required = false) String endTime,
	                                            @RequestParam(value = "otherParamsJson", required = false) String otherParamsJson,
	                                            @RequestParam("pageNo") Integer pageNo,
	                                            @RequestParam("pageSize") Integer pageSize) {
	
	        checkPageParams(pageNo, pageSize);
	        searchVal = ParameterUtils.handleEscapes(searchVal);
	        return workflowInstanceService.queryWorkflowInstanceList(loginUser, projectCode, workflowDefinitionCode,
	                startTime,
	                endTime,
	                searchVal, executorName, stateType, host, otherParamsJson, pageNo, pageSize);
	    }
	
	    /**
	     * query task list by workflow instance id
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param id workflow instance id
	     * @return task list for the workflow instance
	     */
	    @Operation(summary = "queryTaskListByWorkflowInstanceId", description = "QUERY_TASK_LIST_BY_WORKFLOW_INSTANCE_ID_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @GetMapping(value = "/{id}/tasks")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_TASK_LIST_BY_WORKFLOW_INSTANCE_ID_ERROR)
	    public Result queryTaskListByWorkflowInstanceId(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                    @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                                    @PathVariable("id") Integer id) throws IOException {
	        Map<String, Object> result =
	                workflowInstanceService.queryTaskListByWorkflowInstanceId(loginUser, projectCode, id);
	        return returnDataList(result);
	    }
	
	    /**
	     * update workflow instance
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param taskRelationJson workflow task relation json
	     * @param taskDefinitionJson taskDefinitionJson
	     * @param id workflow instance id
	     * @param scheduleTime schedule time
	     * @param syncDefine sync define
	     * @param locations locations
	     * @return update result code
	     */
	    @Operation(summary = "updateWorkflowInstance", description = "UPDATE_WORKFLOW_INSTANCE_NOTES")
	    @Parameters({
	            @Parameter(name = "taskRelationJson", description = "TASK_RELATION_JSON", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "taskDefinitionJson", description = "TASK_DEFINITION_JSON", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "1")),
	            @Parameter(name = "scheduleTime", description = "SCHEDULE_TIME", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "syncDefine", description = "SYNC_DEFINE", required = true, schema = @Schema(implementation = boolean.class, example = "false")),
	            @Parameter(name = "globalParams", description = "WORKFLOW_GLOBAL_PARAMS", schema = @Schema(implementation = String.class, example = "[]")),
	            @Parameter(name = "locations", description = "WORKFLOW_INSTANCE_LOCATIONS", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "timeout", description = "WORKFLOW_TIMEOUT", schema = @Schema(implementation = int.class, example = "0")),
	    })
	    @PutMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.UPDATE_WORKFLOW_INSTANCE_ERROR)
	    @OperatorLog(auditType = AuditType.WORKFLOW_INSTANCE_UPDATE)
	    public Result updateWorkflowInstance(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                         @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                         @RequestParam(value = "taskRelationJson", required = true) String taskRelationJson,
	                                         @RequestParam(value = "taskDefinitionJson", required = true) String taskDefinitionJson,
	                                         @PathVariable(value = "id") Integer id,
	                                         @RequestParam(value = "scheduleTime", required = false) String scheduleTime,
	                                         @RequestParam(value = "syncDefine", required = true) Boolean syncDefine,
	                                         @RequestParam(value = "globalParams", required = false, defaultValue = "[]") String globalParams,
	                                         @RequestParam(value = "locations", required = false) String locations,
	                                         @RequestParam(value = "timeout", required = false, defaultValue = "0") int timeout) {
	        Map<String, Object> result = workflowInstanceService.updateWorkflowInstance(loginUser, projectCode, id,
	                taskRelationJson, taskDefinitionJson, scheduleTime, syncDefine, globalParams, locations, timeout);
	        return returnDataList(result);
	    }
	
	    /**
	     * query workflow instance by id
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param id workflow instance id
	     * @return workflow instance detail
	     */
	    @Operation(summary = "queryWorkflowInstanceById", description = "QUERY_WORKFLOW_INSTANCE_BY_ID_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @GetMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_BY_ID_ERROR)
	    public Result queryWorkflowInstanceById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                            @PathVariable("id") Integer id) {
	        Map<String, Object> result = workflowInstanceService.queryWorkflowInstanceById(loginUser, projectCode, id);
	        return returnDataList(result);
	    }
	
	    /**
	     * query top n workflow instance order by running duration
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param size number of workflow instance
	     * @param startTime start time
	     * @param endTime end time
	     * @return list of workflow instance
	     */
	    @Operation(summary = "queryTopNLongestRunningWorkflowInstance", description = "QUERY_TOPN_LONGEST_RUNNING_WORKFLOW_INSTANCE_NOTES")
	    @Parameters({
	            @Parameter(name = "size", description = "WORKFLOW_INSTANCE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "10")),
	            @Parameter(name = "startTime", description = "WORKFLOW_INSTANCE_START_TIME", required = true, schema = @Schema(implementation = String.class)),
	            @Parameter(name = "endTime", description = "WORKFLOW_INSTANCE_END_TIME", required = true, schema = @Schema(implementation = String.class)),
	    })
	    @GetMapping(value = "/top-n")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_BY_ID_ERROR)
	    public Result<WorkflowInstance> queryTopNLongestRunningWorkflowInstance(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                                            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                                                            @RequestParam("size") Integer size,
	                                                                            @RequestParam(value = "startTime", required = true) String startTime,
	                                                                            @RequestParam(value = "endTime", required = true) String endTime) {
	        Map<String, Object> result = workflowInstanceService.queryTopNLongestRunningWorkflowInstance(loginUser,
	                projectCode, size, startTime, endTime);
	        return returnDataList(result);
	    }
	
	    /**
	     * delete workflow instance by id, at the same time,
	     * delete task instance and their mapping relation data
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param id workflow instance id
	     * @return delete result code
	     */
	    @Operation(summary = "deleteWorkflowInstanceById", description = "DELETE_WORKFLOW_INSTANCE_BY_ID_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @DeleteMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.DELETE_WORKFLOW_INSTANCE_BY_ID_ERROR)
	    @OperatorLog(auditType = AuditType.WORKFLOW_INSTANCE_DELETE)
	    public Result<Void> deleteWorkflowInstanceById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                   @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                                   @PathVariable("id") Integer id) {
	        workflowInstanceService.deleteWorkflowInstanceById(loginUser, id);
	        return Result.success();
	    }
	
	    /**
	     * query sub workflow instance detail info by task id
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param taskId task id
	     * @return sub workflow instance detail
	     */
	    @Operation(summary = "querySubWorkflowInstanceByTaskCode", description = "QUERY_SUB_WORKFLOW_INSTANCE_BY_TASK_CODE_NOTES")
	    @Parameters({
	            @Parameter(name = "taskCode", description = "TASK_CODE", required = true, schema = @Schema(implementation = long.class, example = "100"))
	    })
	    @GetMapping(value = "/query-sub-by-parent")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_SUB_WORKFLOW_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR)
	    public Result querySubWorkflowInstanceByTaskId(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                   @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                                   @RequestParam("taskId") Integer taskId) {
	        Map<String, Object> result =
	                workflowInstanceService.querySubWorkflowInstanceByTaskId(loginUser, projectCode, taskId);
	        return returnDataList(result);
	    }
	
	    /**
	     * query parent workflow instance detail info by sub workflow instance id
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param subId sub workflow id
	     * @return parent instance detail
	     */
	    @Operation(summary = "queryParentInstanceBySubId", description = "QUERY_PARENT_WORKFLOW_INSTANCE_BY_SUB_WORKFLOW_INSTANCE_ID_NOTES")
	    @Parameters({
	            @Parameter(name = "subId", description = "SUB_WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @GetMapping(value = "/query-parent-by-sub")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_PARENT_WORKFLOW_INSTANCE_DETAIL_INFO_BY_SUB_WORKFLOW_INSTANCE_ID_ERROR)
	    public Result queryParentInstanceBySubId(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                             @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                             @RequestParam("subId") Integer subId) {
	        Map<String, Object> result = workflowInstanceService.queryParentInstanceBySubId(loginUser, projectCode, subId);
	        return returnDataList(result);
	    }
	
	    /**
	     * query dynamic sub workflow instance detail info by task id
	     *
	     * @param loginUser login user
	     * @param taskId task id
	     * @return sub workflow instance detail
	     */
	    @Operation(summary = "queryDynamicSubWorkflowInstances", description = "QUERY_DYNAMIC_SUB_WORKFLOW_INSTANCE_BY_TASK_CODE_NOTES")
	    @Parameters({
	            @Parameter(name = "taskId", description = "taskInstanceId", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @GetMapping(value = "/query-dynamic-sub-workflows")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_SUB_WORKFLOW_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR)
	    public Result<List<DynamicSubWorkflowDto>> queryDynamicSubWorkflowInstances(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                                                @RequestParam("taskId") Integer taskId) {
	        List<DynamicSubWorkflowDto> dynamicSubWorkflowDtos =
	                workflowInstanceService.queryDynamicSubWorkflowInstances(loginUser, taskId);
	        return new Result(Status.SUCCESS.getCode(), Status.SUCCESS.getMsg(), dynamicSubWorkflowDtos);
	    }
	
	    /**
	     * query workflow instance global variables and local variables
	     *
	     * @param loginUser login user
	     * @param id workflow instance id
	     * @return variables data
	     */
	    @Operation(summary = "viewVariables", description = "QUERY_WORKFLOW_INSTANCE_GLOBAL_VARIABLES_AND_LOCAL_VARIABLES_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @GetMapping(value = "/{id}/view-variables")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.QUERY_WORKFLOW_INSTANCE_ALL_VARIABLES_ERROR)
	    public Result viewVariables(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                                @PathVariable("id") Integer id) {
	        Map<String, Object> result = workflowInstanceService.viewVariables(projectCode, id);
	        return returnDataList(result);
	    }
	
	    /**
	     * encapsulation gantt structure
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param id workflow instance id
	     * @return gantt tree data
	     */
	    @Operation(summary = "vieGanttTree", description = "VIEW_GANTT_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "WORKFLOW_INSTANCE_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @GetMapping(value = "/{id}/view-gantt")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.ENCAPSULATION_WORKFLOW_INSTANCE_GANTT_STRUCTURE_ERROR)
	    public Result viewTree(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                           @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true) @PathVariable long projectCode,
	                           @PathVariable("id") Integer id) throws Exception {
	        Map<String, Object> result = workflowInstanceService.viewGantt(projectCode, id);
	        return returnDataList(result);
	    }
	
	    /**
	     * batch delete workflow instance by ids, at the same time,
	     * delete task instance and their mapping relation data
	     *
	     * @param loginUser login user
	     * @param projectCode project code
	     * @param workflowInstanceIds workflow instance id
	     * @return delete result code
	     */
	    @Operation(summary = "batchDeleteWorkflowInstanceByIds", description = "BATCH_DELETE_WORKFLOW_INSTANCE_BY_IDS_NOTES")
	    @Parameters({
	            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true, schema = @Schema(implementation = int.class)),
	            @Parameter(name = "workflowInstanceIds", description = "WORKFLOW_INSTANCE_IDS", required = true, schema = @Schema(implementation = String.class)),
	    })
	    @PostMapping(value = "/batch-delete")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(Status.BATCH_DELETE_WORKFLOW_INSTANCE_BY_IDS_ERROR)
	    @OperatorLog(auditType = AuditType.WORKFLOW_INSTANCE_BATCH_DELETE)
	    public Result batchDeleteWorkflowInstanceByIds(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                   @PathVariable long projectCode,
	                                                   @RequestParam("workflowInstanceIds") String workflowInstanceIds) {
	        // task queue
	        Map<String, Object> result = new HashMap<>();
	        List<String> deleteFailedIdList = new ArrayList<>();
	        if (!StringUtils.isEmpty(workflowInstanceIds)) {
	            String[] workflowInstanceIdArray = workflowInstanceIds.split(Constants.COMMA);
	
	            for (String strWorkflowInstanceId : workflowInstanceIdArray) {
	                int workflowInstanceId = Integer.parseInt(strWorkflowInstanceId);
	                try {
	                    workflowInstanceService.deleteWorkflowInstanceById(loginUser, workflowInstanceId);
	                } catch (Exception e) {
	                    log.error("Delete workflow instance: {} error", strWorkflowInstanceId, e);
	                    deleteFailedIdList
	                            .add(MessageFormat.format(Status.WORKFLOW_INSTANCE_ERROR.getMsg(), strWorkflowInstanceId));
	                }
	            }
	        }
	        if (!deleteFailedIdList.isEmpty()) {
	            putMsg(result, Status.BATCH_DELETE_WORKFLOW_INSTANCE_BY_IDS_ERROR, String.join("
	", deleteFailedIdList));
	        } else {
	            putMsg(result, Status.SUCCESS);
	        }
	        return returnDataList(result);
	    }
	
	    // Todo: This is unstable, in some case the command trigger failed, we cannot get workflow instance
	    // And it's a bad design to use trigger code to get workflow instance why not directly get by workflow instanceId or
	    // inject the trigger id into workflow instance?
	    @Deprecated
	    @Operation(summary = "queryWorkflowInstanceListByTrigger", description = "QUERY_WORKFLOW_INSTANCE_BY_TRIGGER_NOTES")
	    @Parameters({
	            @Parameter(name = "projectCode", description = "PROJECT_CODE", required = true, schema = @Schema(implementation = Long.class)),
	            @Parameter(name = "triggerCode", description = "TRIGGER_CODE", required = true, schema = @Schema(implementation = Long.class))
	    })
	    @GetMapping("/trigger")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_WORKFLOW_INSTANCE_LIST_PAGING_ERROR)
	    public Result queryWorkflowInstancesByTriggerCode(@RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                      @PathVariable long projectCode,
	                                                      @RequestParam(value = "triggerCode") Long triggerCode) {
	        Map<String, Object> result = workflowInstanceService.queryByTriggerCode(loginUser, projectCode, triggerCode);
	        return returnDataList(result);
	    }
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/WorkflowInstanceService.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.service;
	
	import org.apache.dolphinscheduler.api.dto.DynamicSubWorkflowDto;
	import org.apache.dolphinscheduler.api.dto.workflowInstance.WorkflowInstanceQueryRequest;
	import org.apache.dolphinscheduler.api.utils.PageInfo;
	import org.apache.dolphinscheduler.api.utils.Result;
	import org.apache.dolphinscheduler.common.enums.WorkflowExecutionStatus;
	import org.apache.dolphinscheduler.dao.entity.User;
	import org.apache.dolphinscheduler.dao.entity.WorkflowInstance;
	
	import java.io.IOException;
	import java.util.List;
	import java.util.Map;
	
	public interface WorkflowInstanceService {
	
	    /**
	     * return top n SUCCESS workflow instance order by running time which started between startTime and endTime
	     */
	    Map<String, Object> queryTopNLongestRunningWorkflowInstance(User loginUser,
	                                                                long projectCode,
	                                                                int size,
	                                                                String startTime,
	                                                                String endTime);
	
	    /**
	     * query workflow instance by id
	     *
	     * @param loginUser   login user
	     * @param projectCode project code
	     * @param workflowInstanceId   workflow instance id
	     * @return workflow instance detail
	     */
	    Map<String, Object> queryWorkflowInstanceById(User loginUser,
	                                                  long projectCode,
	                                                  Integer workflowInstanceId);
	
	    WorkflowInstance queryByWorkflowInstanceIdThrowExceptionIfNotFound(Integer workflowInstanceId);
	
	    /**
	     * query workflow instance by id
	     *
	     * @param loginUser login user
	     * @param workflowInstanceId workflow instance id
	     * @return workflow instance detail
	     */
	    Map<String, Object> queryWorkflowInstanceById(User loginUser,
	                                                  Integer workflowInstanceId);
	
	    /**
	     * paging query workflow instance list, filtering according to project, workflow definition, time range, keyword, workflow status
	     *
	     * @param loginUser         login user
	     * @param projectCode       project code
	     * @param pageNo            page number
	     * @param pageSize          page size
	     * @param workflowDefinitionCode workflow definition code
	     * @param searchVal         search value
	     * @param stateType         state type
	     * @param host              host
	     * @param startDate         start time
	     * @param endDate           end time
	     * @param otherParamsJson   otherParamsJson handle other params
	     * @return workflow instance list
	     */
	    Result<PageInfo<WorkflowInstance>> queryWorkflowInstanceList(User loginUser,
	                                                                 long projectCode,
	                                                                 long workflowDefinitionCode,
	                                                                 String startDate,
	                                                                 String endDate,
	                                                                 String searchVal,
	                                                                 String executorName,
	                                                                 WorkflowExecutionStatus stateType,
	                                                                 String host,
	                                                                 String otherParamsJson,
	                                                                 Integer pageNo,
	                                                                 Integer pageSize);
	
	    /**
	     * paging query workflow instance list, filtering according to project, workflow definition, time range, keyword, workflow status
	     *
	     * @param loginUser                    login user
	     * @param workflowInstanceQueryRequest workflowInstanceQueryRequest
	     * @return workflow instance list
	     */
	    Result queryWorkflowInstanceList(User loginUser,
	                                     WorkflowInstanceQueryRequest workflowInstanceQueryRequest);
	
	    /**
	     * query task list by workflow instance id
	     *
	     * @param loginUser   login user
	     * @param projectCode project code
	     * @param workflowInstanceId   workflow instance id
	     * @return task list for the workflow instance
	     * @throws IOException io exception
	     */
	    Map<String, Object> queryTaskListByWorkflowInstanceId(User loginUser,
	                                                          long projectCode,
	                                                          Integer workflowInstanceId) throws IOException;
	
	    /**
	     * query sub workflow instance detail info by task id
	     *
	     * @param loginUser   login user
	     * @param projectCode project code
	     * @param taskId      task id
	     * @return sub workflow instance detail
	     */
	    Map<String, Object> querySubWorkflowInstanceByTaskId(User loginUser,
	                                                         long projectCode,
	                                                         Integer taskId);
	
	    List<DynamicSubWorkflowDto> queryDynamicSubWorkflowInstances(User loginUser,
	                                                                 Integer taskId);
	
	    /**
	     * update workflow instance
	     *
	     * @param loginUser          login user
	     * @param projectCode        project code
	     * @param taskRelationJson   workflow task relation json
	     * @param taskDefinitionJson taskDefinitionJson
	     * @param workflowInstanceId  workflow instance id
	     * @param scheduleTime       schedule time
	     * @param syncDefine         sync define
	     * @param globalParams       global params
	     * @param locations          locations for nodes
	     * @param timeout            timeout
	     * @return update result code
	     */
	    Map<String, Object> updateWorkflowInstance(User loginUser,
	                                               long projectCode,
	                                               Integer workflowInstanceId,
	                                               String taskRelationJson,
	                                               String taskDefinitionJson,
	                                               String scheduleTime,
	                                               Boolean syncDefine,
	                                               String globalParams,
	                                               String locations,
	                                               int timeout);
	
	    /**
	     * query parent workflow instance detail info by sub workflow instance id
	     *
	     * @param loginUser   login user
	     * @param projectCode project code
	     * @param subId       sub workflow id
	     * @return parent instance detail
	     */
	    Map<String, Object> queryParentInstanceBySubId(User loginUser,
	                                                   long projectCode,
	                                                   Integer subId);
	
	    /**
	     * delete workflow instance by id, at the same timedelete task instance and their mapping relation data
	     *
	     * @param loginUser         login user
	     * @param workflowInstanceId workflow instance id
	     * @return delete result code
	     */
	    void deleteWorkflowInstanceById(User loginUser,
	                                    Integer workflowInstanceId);
	
	    /**
	     * view workflow instance variables
	     *
	     * @param projectCode       project code
	     * @param workflowInstanceId workflow instance id
	     * @return variables data
	     */
	    Map<String, Object> viewVariables(long projectCode, Integer workflowInstanceId);
	
	    /**
	     * encapsulation gantt structure
	     *
	     * @param projectCode       project code
	     * @param workflowInstanceId workflow instance id
	     * @return gantt tree data
	     * @throws Exception exception when json parse
	     */
	    Map<String, Object> viewGantt(long projectCode, Integer workflowInstanceId) throws Exception;
	
	    /**
	     * query workflow instance by workflowDefinitionCode and stateArray
	     *
	     * @param workflowDefinitionCode workflowDefinitionCode
	     * @param states                states array
	     * @return workflow instance list
	     */
	    List<WorkflowInstance> queryByWorkflowDefinitionCodeAndStatus(Long workflowDefinitionCode,
	                                                                  int[] states);
	
	    /**
	     * query workflow instance by workflowDefinitionCode and stateArray
	     *
	     * @param workflowDefinitionCode    workflowDefinitionCode
	     * @param workflowDefinitionVersion workflowDefinitionVersion
	     * @param states                    states array
	     * @return workflow instance list
	     */
	    List<WorkflowInstance> queryByWorkflowCodeVersionStatus(Long workflowDefinitionCode,
	                                                            int workflowDefinitionVersion,
	                                                            int[] states);
	
	    /**
	     * query workflow instance by workflowDefinitionCode
	     *
	     * @param workflowDefinitionCode workflowDefinitionCode
	     * @param size                  size
	     * @return workflow instance list
	     */
	    List<WorkflowInstance> queryByWorkflowDefinitionCode(Long workflowDefinitionCode,
	                                                         int size);
	
	    /**
	     * query workflow instance list bt trigger code
	     *
	     * @param loginUser
	     * @param projectCode
	     * @param triggerCode
	     * @return
	     */
	    Map<String, Object> queryByTriggerCode(User loginUser, long projectCode, Long triggerCode);
	
	    void deleteWorkflowInstanceByWorkflowDefinitionCode(long workflowDefinitionCode);
	
	    void deleteWorkflowInstanceById(int workflowInstanceId);
	
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AlertGroupController.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.api.controller;
	
	import static org.apache.dolphinscheduler.api.enums.Status.CREATE_ALERT_GROUP_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.DELETE_ALERT_GROUP_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.LIST_PAGING_ALERT_GROUP_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ALERT_GROUP_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.QUERY_ALL_ALERTGROUP_ERROR;
	import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_ALERT_GROUP_ERROR;
	
	import org.apache.dolphinscheduler.api.audit.OperatorLog;
	import org.apache.dolphinscheduler.api.audit.enums.AuditType;
	import org.apache.dolphinscheduler.api.enums.Status;
	import org.apache.dolphinscheduler.api.exceptions.ApiException;
	import org.apache.dolphinscheduler.api.service.AlertGroupService;
	import org.apache.dolphinscheduler.api.utils.PageInfo;
	import org.apache.dolphinscheduler.api.utils.Result;
	import org.apache.dolphinscheduler.common.constants.Constants;
	import org.apache.dolphinscheduler.dao.entity.AlertGroup;
	import org.apache.dolphinscheduler.dao.entity.User;
	import org.apache.dolphinscheduler.plugin.task.api.utils.ParameterUtils;
	
	import java.util.List;
	
	import lombok.extern.slf4j.Slf4j;
	
	import org.springframework.beans.factory.annotation.Autowired;
	import org.springframework.http.HttpStatus;
	import org.springframework.web.bind.annotation.DeleteMapping;
	import org.springframework.web.bind.annotation.GetMapping;
	import org.springframework.web.bind.annotation.PathVariable;
	import org.springframework.web.bind.annotation.PostMapping;
	import org.springframework.web.bind.annotation.PutMapping;
	import org.springframework.web.bind.annotation.RequestAttribute;
	import org.springframework.web.bind.annotation.RequestMapping;
	import org.springframework.web.bind.annotation.RequestParam;
	import org.springframework.web.bind.annotation.ResponseStatus;
	import org.springframework.web.bind.annotation.RestController;
	
	import io.swagger.v3.oas.annotations.Operation;
	import io.swagger.v3.oas.annotations.Parameter;
	import io.swagger.v3.oas.annotations.Parameters;
	import io.swagger.v3.oas.annotations.media.Schema;
	import io.swagger.v3.oas.annotations.tags.Tag;
	
	/**
	 * alert group controller
	 */
	@Tag(name = "ALERT_GROUP_TAG")
	@RestController
	@RequestMapping("/alert-groups")
	@Slf4j
	public class AlertGroupController extends BaseController {
	
	    @Autowired
	    private AlertGroupService alertGroupService;
	
	    /**
	     * create alert group
	     *
	     * @param loginUser login user
	     * @param groupName group name
	     * @param description description
	     * @return create result code
	     */
	    @Operation(summary = "createAlertGroup", description = "CREATE_ALERT_GROUP_NOTES")
	    @Parameters({
	            @Parameter(name = "groupName", description = "GROUP_NAME", required = true, schema = @Schema(implementation = String.class)),
	            @Parameter(name = "description", description = "DESC", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "alertInstanceIds", description = "alertInstanceIds", required = true, schema = @Schema(implementation = String.class))
	    })
	    @PostMapping()
	    @ResponseStatus(HttpStatus.CREATED)
	    @ApiException(CREATE_ALERT_GROUP_ERROR)
	    @OperatorLog(auditType = AuditType.ALARM_GROUP_CREATE)
	    public Result<AlertGroup> createAlertGroup(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                               @RequestParam(value = "groupName") String groupName,
	                                               @RequestParam(value = "description", required = false) String description,
	                                               @RequestParam(value = "alertInstanceIds") String alertInstanceIds) {
	        AlertGroup alertgroup = alertGroupService.createAlertGroup(loginUser, groupName, description, alertInstanceIds);
	        return Result.success(alertgroup);
	    }
	
	    /**
	     * alert group list
	     *
	     * @param loginUser login user
	     * @return alert group list
	     */
	    @Operation(summary = "listAlertGroupById", description = "QUERY_ALERT_GROUP_LIST_NOTES")
	    @GetMapping(value = "/list")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_ALL_ALERTGROUP_ERROR)
	    public Result<List<AlertGroup>> list(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {
	
	        List<AlertGroup> alertGroups = alertGroupService.queryAllAlertGroup(loginUser);
	        return Result.success(alertGroups);
	    }
	
	    /**
	     * paging query alarm group list
	     *
	     * @param loginUser login user
	     * @param pageNo page number
	     * @param searchVal search value
	     * @param pageSize page size
	     * @return alert group list page
	     */
	    @Operation(summary = "queryAlertGroupListPaging", description = "QUERY_ALERT_GROUP_LIST_PAGING_NOTES")
	    @Parameters({
	            @Parameter(name = "searchVal", description = "SEARCH_VAL", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "pageNo", description = "PAGE_NO", required = true, schema = @Schema(implementation = int.class, example = "1")),
	            @Parameter(name = "pageSize", description = "PAGE_SIZE", required = true, schema = @Schema(implementation = int.class, example = "20"))
	    })
	    @GetMapping()
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(LIST_PAGING_ALERT_GROUP_ERROR)
	    public Result<PageInfo<AlertGroup>> listPaging(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                   @RequestParam(value = "searchVal", required = false) String searchVal,
	                                                   @RequestParam("pageNo") Integer pageNo,
	                                                   @RequestParam("pageSize") Integer pageSize) {
	        checkPageParams(pageNo, pageSize);
	        searchVal = ParameterUtils.handleEscapes(searchVal);
	        PageInfo<AlertGroup> alertGroupPageInfo = alertGroupService.listPaging(loginUser, searchVal, pageNo, pageSize);
	        return Result.success(alertGroupPageInfo);
	    }
	
	    /**
	     * check alarm group detail by id
	     *
	     * @param loginUser login user
	     * @param id        alert group id
	     * @return one alert group
	     */
	
	    @Operation(summary = "queryAlertGroupById", description = "QUERY_ALERT_GROUP_BY_ID_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "ALERT_GROUP_ID", schema = @Schema(implementation = int.class, example = "1"))
	    })
	    @PostMapping(value = "/query")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(QUERY_ALERT_GROUP_ERROR)
	    public Result<AlertGroup> queryAlertGroupById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                  @RequestParam("id") Integer id) {
	
	        AlertGroup alertGroup = alertGroupService.queryAlertGroupById(loginUser, id);
	        return Result.success(alertGroup);
	    }
	
	    /**
	     * updateWorkflowInstance alert group
	     *
	     * @param loginUser login user
	     * @param id alert group id
	     * @param groupName group name
	     * @param description description
	     * @return update result code
	     */
	    @Operation(summary = "updateAlertGroup", description = "UPDATE_ALERT_GROUP_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "ALERT_GROUP_ID", required = true, schema = @Schema(implementation = int.class, example = "100")),
	            @Parameter(name = "groupName", description = "GROUP_NAME", required = true, schema = @Schema(implementation = String.class)),
	            @Parameter(name = "description", description = "DESC", schema = @Schema(implementation = String.class)),
	            @Parameter(name = "alertInstanceIds", description = "ALERT_INSTANCE_IDS", required = true, schema = @Schema(implementation = String.class))
	    })
	    @PutMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(UPDATE_ALERT_GROUP_ERROR)
	    @OperatorLog(auditType = AuditType.ALARM_GROUP_UPDATE)
	    public Result<AlertGroup> updateAlertGroupById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                   @PathVariable(value = "id") int id,
	                                                   @RequestParam(value = "groupName") String groupName,
	                                                   @RequestParam(value = "description", required = false) String description,
	                                                   @RequestParam(value = "alertInstanceIds") String alertInstanceIds) {
	        AlertGroup alertGroup =
	                alertGroupService.updateAlertGroupById(loginUser, id, groupName, description, alertInstanceIds);
	        return Result.success(alertGroup);
	    }
	
	    /**
	     * delete alert group by id
	     *
	     * @param loginUser login user
	     * @param id alert group id
	     * @return delete result code
	     */
	    @Operation(summary = "delAlertGroupById", description = "DELETE_ALERT_GROUP_BY_ID_NOTES")
	    @Parameters({
	            @Parameter(name = "id", description = "ALERT_GROUP_ID", required = true, schema = @Schema(implementation = int.class, example = "100"))
	    })
	    @DeleteMapping(value = "/{id}")
	    @ResponseStatus(HttpStatus.OK)
	    @ApiException(DELETE_ALERT_GROUP_ERROR)
	    @OperatorLog(auditType = AuditType.ALARM_GROUP_DELETE)
	    public Result<Boolean> deleteAlertGroupById(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                                @PathVariable(value = "id") int id) {
	        alertGroupService.deleteAlertGroupById(loginUser, id);
	        return Result.success(true);
	    }
	
	    /**
	     * check alert group exist
	     *
	     * @param loginUser login user
	     * @param groupName group name
	     * @return check result code
	     */
	    @Operation(summary = "verifyGroupName", description = "VERIFY_ALERT_GROUP_NAME_NOTES")
	    @Parameters({
	            @Parameter(name = "groupName", description = "GROUP_NAME", required = true, schema = @Schema(implementation = String.class)),
	    })
	    @GetMapping(value = "/verify-name")
	    @ResponseStatus(HttpStatus.OK)
	    public Result verifyGroupName(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
	                                  @RequestParam(value = "groupName") String groupName) {
	
	        boolean exist = alertGroupService.existGroupName(groupName);
	        Result result = new Result();
	        if (exist) {
	            log.error("group {} has exist, can't create again.", groupName);
	            result.setCode(Status.ALERT_GROUP_EXIST.getCode());
	            result.setMsg(Status.ALERT_GROUP_EXIST.getMsg());
	        } else {
	            result.setCode(Status.SUCCESS.getCode());
	            result.setMsg(Status.SUCCESS.getMsg());
	        }
	        return result;
	    }
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/EnvironmentWorkerGroupRelation.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.dao.entity;
	
	import java.util.Date;
	
	import lombok.Data;
	
	import com.baomidou.mybatisplus.annotation.IdType;
	import com.baomidou.mybatisplus.annotation.TableId;
	import com.baomidou.mybatisplus.annotation.TableName;
	
	@Data
	@TableName("t_ds_environment_worker_group_relation")
	public class EnvironmentWorkerGroupRelation {
	
	    @TableId(value = "id", type = IdType.AUTO)
	    private Integer id;
	
	    /**
	     * environment code
	     */
	    private Long environmentCode;
	
	    /**
	     * worker group id
	     */
	    private String workerGroup;
	
	    /**
	     * operator user id
	     */
	    private Integer operator;
	
	    private Date createTime;
	
	    private Date updateTime;
	}
		
",
	role:"
	user	
",
,
	content:"
	//dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/ProjectWorkerGroup.java
	/*
	 * Licensed to the Apache Software Foundation (ASF) under one or more
	 * contributor license agreements.  See the NOTICE file distributed with
	 * this work for additional information regarding copyright ownership.
	 * The ASF licenses this file to You under the Apache License, Version 2.0
	 * (the "License"); you may not use this file except in compliance with
	 * the License.  You may obtain a copy of the License at
	 *
	 *    http://www.apache.org/licenses/LICENSE-2.0
	 *
	 * Unless required by applicable law or agreed to in writing, software
	 * distributed under the License is distributed on an "AS IS" BASIS,
	 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
	 * See the License for the specific language governing permissions and
	 * limitations under the License.
	 */
	
	package org.apache.dolphinscheduler.dao.entity;
	
	import java.util.Date;
	
	import lombok.Data;
	
	import com.baomidou.mybatisplus.annotation.IdType;
	import com.baomidou.mybatisplus.annotation.TableId;
	import com.baomidou.mybatisplus.annotation.TableName;
	
	@Data
	@TableName("t_ds_relation_project_worker_group")
	public class ProjectWorkerGroup {
	
	    /**
	     * id
	     */
	    @TableId(value = "id", type = IdType.AUTO)
	    private Integer id;
	
	    /**
	     * project code
	     */
	    private Long projectCode;
	
	    /**
	     * worker group
	     */
	    private String workerGroup;
	
	    /**
	     * create time
	     */
	    private Date createTime;
	
	    /**
	     * update time
	     */
	    private Date updateTime;
	}
		
",
	role:"
	user	
",
,

],
model:"
gpt-4-1106-preview
",
response_format:
{
	type:"
	json_object	
",

}
temperature:"0.5",
